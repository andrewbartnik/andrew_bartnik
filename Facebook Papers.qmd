---
title: "Data Justice and the Facebook Papers"
description: "Taking a look at how the internal documents leaked from facebook reveal new data justice issues that we must confront"
author:
  - name: Andrew Bartnik
    url: https://andrewbartnik.github.io/
    affiliation: Master of Environmental Data Science Program @ The Bren School (UCSB)
    affiliation-url: https://ucsb-meds.github.io/ 
date: 12-04-2022
categories: [Projects,] # self-defined categories
citation: 
  url: https://andrewbartnik.github.io/Portfolio/facebook-papers
image: img.jpeg
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
---

# Introduction

As we proceed towards a future increasingly dictated by data-driven decisions, we are faced with a myriad of new ethical issues that must be addressed. It's hard to imagine that those with access to environmental data will not have to make the same decisions made by big tech companies. User data has become the life blood for the tech giants of surveillance capitalism, and their profits are consistently chosen over the well-being of their users and society as a whole. This post will examine the facebook papers, and explore the consequences for data justice in an algorithmically manipulated world.

# The Facebook Papers

Beginning in September 2021, the Wall Street Journal began to publish reports investigating internal Facebook (Now known as Meta) documents leaked by ex employee turned whistleblower Francis Haugen[^1]. The reports reveal the grim reality of how facebook uses its user data to figure out how to keep their userson their plaform for as long as possible. The consequences to Facebook's approach to maximize engagement are much more far-reaching than users spending too much unintended time on the platform. The consistent theme throughout every decision made by the company is that employees and executives knew that what they were doing was wrong, but addressing these problems would require facebook to tweak their algorithms to result in less user-engagement - therefore cutting profits. The company's short term profits were consistently chosen over addressing its problems.

## Misinformation

Facebook uses a strike system to manage misinformation circulated on the app. Too many strikes in a 90-day period can result in a user being suspended from posting content, and reductions in circulation and advertisement revenue. However, accounts with large followings are given special treatment, as is the case with Breitbart, a well-known right-wing conspiratorial news site. Former president Donald Trump posted a video posted by Breitbart that encouraged viewers not to wear a mask for COVID-19 and to take hydroxychloroquine instead. Despite clearly violating their misinformation policy, the video was allowed to circulate and reach millions of people before it was taken down. Meta's CEO, Mark Zuckerberg, claimed that Breitbart wasn't punished for the video, as it was the company's only misinformation violation in a 90-day period[^2]. Breitbart is a 'managed partner' with Facebook, where a facebook employee is assigned to watch the company's posts and alert the company to edit posted material that contains misinformation. This system allows Breitbart to avoid strikes, as long as they edit their content after it has been spread around. Thus, Breitbart gets their content circulated, while Facebook gets to say that they're working to prevent misinformation while profiting off of Breitbart's material. Additionally, facebook executives also allow the removal of strikes to avoid de-listing any right wing managed partners. This is also an example of Facebook not wanting to upset its conservative users - allowing misinformation to spread instead. One employee wrote in the company's internal chat: "We are apparently providing hate-speech-policy-consulting and consequence-mitigation services to select partners"[^3].


[^1]: https://www.wsj.com/articles/facebook-whistleblower-frances-haugen-says-she-wants-to-fix-the-company-not-harm-it-11633304122?mod=article_inline
[^2]: https://www.washingtonpost.com/business/2021/10/26/conservative-media-misinformation-facebook/
[^3]: https://www.wsj.com/articles/facebook-politics-decision-making-documents-11635100195
