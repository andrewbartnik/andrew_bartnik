---
title: "Biodiversity Sentiment Analysis"
description: "I used the Nexis Uni database to analyze the sentiment associated with Biodiversity. This assignment was part of EDS 231 - Text and Sentiment Analysis for Environmental Science"
author:
  - name: Andrew Bartnik
    url: https://andrewbartnik.github.io/
    affiliation: Master of Environmental Data Science Program @ The Bren School (UCSB)
    affiliation-url: https://ucsb-meds.github.io/ 
date: 08-01-2023
categories: [NLP, R, Assignments] # self-defined categories
image: bd.jpeg
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
format: 
  html: 
    code-fold: false
    toc: true
editor: visual
engine: knitr
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(LexisNexisTools)
library(dplyr)
library(readr)
library(stringr)
library(here)
library(tidytext)
library(tidyr) #pivot_wider()
library(ggplot2)
```

I first accessed the Nexis Uni database through the UCSB library. I then chose to search for articles related to biodiversity and downloaded a batch of 100 .docx files.

<https://github.com/JBGruber/LexisNexisTools/wiki/Downloading-Files-From-Nexis>

```{r, warning=FALSE, message=FALSE}

# Reading in files
pre_files <- list.files(pattern = ".docx", 
                        path = "/Users/andrewbartnik/Desktop/misc/MEDS/Spring/text/text_analysis/data/lab2/files2",
                       full.names = TRUE, 
                       recursive = TRUE, 
                       ignore.case = TRUE)

# Saving objects
pre_dat <- lnt_read(pre_files)
bing_sent <- get_sentiments('bing')
nrc_sent <- get_sentiments("nrc")


```

I cleaned artifacts of the data collection process (date strings, etc), and saved the metadata, article title, and paragraph contents to their own objects - adding this all together into a dataframe.

```{r, warning=FALSE, message=FALSE}

meta <- pre_dat@meta
articles <- pre_dat@articles
paragraphs <- pre_dat@paragraphs

data <- tibble(Date = meta$Date, Headline = meta$Headline, id = pre_dat@articles$ID, text = pre_dat@articles$Article)

head(data)
```

Exploring the data a bit!

```{r, warning=FALSE, message=FALSE}
# date freq
date_freq <- data %>%
  group_by(Date) %>%
  summarise(freq = n())

ggplot(date_freq, aes(x = Date, y = freq)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  labs(x = "Date", y = "Frequency", title = "Frequency of Dates 2022-2023") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Here, I'm unnesting each word in the article and joining them to their bing sentiment scores.

```{r, warning=FALSE, message=FALSE}
# Extract words
text <- data |> unnest_tokens(output = word, input = text, token = 'words')

# join to sent 
sent_words <- text |> 
  anti_join(stop_words, by = "word") |> 
  inner_join(bing_sent, by = 'word') |> 
  mutate(sent_num = case_when(sentiment == "negative" ~ -1, sentiment == "positive" ~ 1))
```

We can calculate the average sentiment for each article

```{r, warning=FALSE, message=FALSE}
sent_article2 <-sent_words |> 
  count(id, sentiment) |> 
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) |> 
  mutate(polarity = positive - negative) 
mean(sent_article2$polarity)

```

Now we can look at the distribution of sentiments across all the articles:

```{r, warning=FALSE, message=FALSE}
ggplot(sent_article2, aes(x = id)) + 
  theme_classic() + 
  geom_col(aes(y = positive), stat = 'identity', fill = 'lightblue') + 
  geom_col(aes(y = negative), stat = 'identity', fill = 'red', alpha = 0.5) + 
  labs(title = 'Sentiment analysis: Biodiversity', y = "Sentiment Score")
```

And for the fun part - after we filter out stop words, we can join our words to the `nrc_sent` object which shows the associated sentiment for each word:

```{r, warning=FALSE, message=FALSE}
nrc_word_counts_bio <- text |> anti_join(stop_words, by = "word") |> inner_join(nrc_sent) |> count(word, sentiment, sort = T) 
```

```{r, warning=FALSE, message=FALSE}
# Now to look at specific nrc sentiments
sent_counts2 <- text |> 
  anti_join(stop_words, by = 'word') |> 
  group_by(id) |> 
  inner_join(nrc_sent) |> 
  group_by(sentiment) |> 
  count(word, sentiment, sort = T)

sent_counts2 |> group_by(sentiment) |> slice_max(n, n = 10) |> ungroup() |> mutate(word = reorder(word, n)) |> ggplot(aes(x=n, y=word, fill = sentiment)) + geom_col(show.legend = FALSE) + facet_wrap(~sentiment, scales= "free_y") + labs(x = "Contribution to sentiment", y = NULL)
```

**"Loss" seems to be associated with strongly negative emotions. Conservation also seems to elicit a strong emotional response.**

**Soil, wind, and diverse are associated with more negative emotions, which is misleading. Since these terms are pretty neutral in this context, we can reclassify their associated sentiments.**

```{r, warning=FALSE, message=FALSE}
sent_counts2 |> filter(!word %in% c("soil", "wind", "diverse")) |> group_by(sentiment) |> slice_max(n, n = 10) |> ungroup() |> mutate(word = reorder(word, n)) |> ggplot(aes(x=n, y=word, fill = sentiment)) + geom_col(show.legend = FALSE) + facet_wrap(~sentiment, scales= "free_y") + labs(x = "Contribution to sentiment", y = NULL)
```

**Thats better, harm and crisis are more appropriately associated with negative sentiment than soil and wind**

Now we can plot the amount of nrc emotion words as a percentage of all the emotion words used each day. Then we can analyze the distribution of emotion words change over time.

```{r, warning=FALSE, message=FALSE}

nrc_emotion_counts <- text %>%
  inner_join(nrc_sent) %>%
  count(Date, sentiment)

# Aggregate the text from articles published on the same day
total_emotions_by_day <- nrc_emotion_counts %>%
  group_by(Date) %>%
  summarise(total = sum(n))

# Calculate the percentage of NRC emotion words per day
nrc_emotion_percentage <- nrc_emotion_counts %>%
  left_join(total_emotions_by_day, by = "Date") %>%
  mutate(percentage = n / total * 100)

# Plot the distribution of emotion words over time
ggplot(nrc_emotion_percentage, aes(x = Date, y = percentage, color = sentiment)) +
  geom_line() +
  theme_minimal() +
  labs(x = "Date", y = "Percentage of Emotion Words", title = "Distribution of Emotion Words Over Time") +
  theme(legend.title = element_blank(), legend.position = "bottom", legend.box = "horizontal")

```

**The sentiment around the biodiversity term is overwhelmingly positive over the given time period. Trust was the second most frequent sentiment. This could be because most of the articles I downloaded were related to conservation efforts and achievements. The only time negative sentiment surpasses positive sentiment was at the end of February, when the only article published within a 6 day period was titled "Majorda locals object to alleged destruction of biodiversity, natural flow of water by RVNL"**
