{
  "hash": "769f7844e6052a32816b55127b4532c3",
  "result": {
    "markdown": "---\ntitle: \"Predicting dissolved inorganic carbon (DIC) concentrations using different algorithms in Python and R\"\ndescription: \"We will use ocean chemistry data collected by CalCOFI to predict DIC using Linear Regression, KNN, Decision Trees, Random Forest Regressor, Gradient Boosting, and a Support Vector Machine.\"\nauthor:\n  - name: Andrew Bartnik\n    url: https://andrewbartnik.github.io/\n    affiliation: Master of Environmental Data Science Program @ The Bren School (UCSB)\n    affiliation-url: https://ucsb-meds.github.io/ \ndate: 03-18-2023\ncategories: [R, Python, ML, Projects] # self-defined categories\ncitation: \n  url: https://andrewbartnik.github.io/Portfolio/ocean-modeling\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\nformat: \n  html: \n    toc: true\neditor: visual\nengine: knitr\ncode-fold: false\n---\n\n\n# Introduction and Background\n\nIn this post we will be using chemistry data from seawater collected by the California Cooperative Oceanic Fisheries Investigation ([CalCOFI](https://calcofi.org/data/oceanographic-data/bottle-database/)). We will be using temperature, salinity, pH, and other chemical parameters to predict Dissolved Inorganic Carbon (DIC) concentrations. Samples are collected at [CalCOFI sampling stations](https://calcofi.org/sampling-info/station-positions/). We will be using different regression models to find which does the best job at predicting DIC. Our models are as follows: Linear Regression (including Ridge and Lasso penalties), K-Nearest Neighbors, Decision Trees, Bagged Decision Trees, Random Forests, Gradient Boosting, and a Support Vector Machine. We will be building each of these models in both Python and R using sklearn and tidymodels, and we will discuss how each of these models work. This is an expansion on an assignment from Machine Learning for Environmental Science as part of the University of California Santa Barbara's Bren School of the Environment & Management Master of Environmental Data Science (MEDS) Program.\n\nThe full list of our predictors are below:\n\n1.  NO2uM - Micromoles of Nitrite per liter of seawater\n\n2.  NO3uM - Micromoles of Nitrate per liter of seawater\n\n3.  NH3uM - Micromoles of Ammonia per liter of seawater\n\n4.  R_TEMP - Reported (Potential) Temperature Celsius\n\n5.  R_Depth - Reported Depth (from pressure, meters)\n\n6.  R_Sal - Reported Salinity (from Specific Volume Anomoly, MÂ³/Kg)\n\n7.  R_DYNHT - Reported Dynamic Height in units of dynamic meters (work per unit mass)\n\n8.  R_Nuts - Reported Ammonium concentration\n\n9.  R_Oxy_micromol.Kg - Reported Oxygen concentration micromoles/kilogram\n\n10. PO4uM - Micromoles of Phosphate per liter of seawater\n\n11. SiO3uM - Micromoles of Silicate per liter of seawater\n\n12. TA1 - Total Alkalinity micromoles per kilogram solution\n\n13. Salinity1 - Salinity (Practical Scale - 1978)\n\n14. Temperature_degC - Temp (C)\n\nFirst, we import our required libraries in both languages. We use the reticulate package in R to allow us to execute python code in a quarto doc.\n\n::: panel-tabset\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gridExtra)\nlibrary(doParallel)\nlibrary(rsample)\nlibrary(glmnet)\nlibrary(tmap)\nlibrary(sf)\nlibrary(leaflet)\nlibrary(reticulate)\nlibrary(baguette)\n\nuse_condaenv(\"oceanchem\", required = TRUE)\n```\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# numpy and pandas for data manipulation + processing\nimport pandas as pd\nimport numpy as np\n\n# sklearn and xgboost for our modeling\nimport xgboost\nimport sklearn\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.svm import SVR\n\n# cartopy, matplotlib for plots\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport plotly\n```\n:::\n\n:::\n\n# Preprocessing\n\nFirst, we are going to do some pre-processing and data exploration. The process is essentially the same in both R and python. We first import the data, and make sure our columns are consistent. The actual `DIC` values for our test set are stored in a separate dataframe, so we'll also join these onto the test set.\n\n::: panel-tabset\n\n### Python\n\nWe first use pandas to read in our data, merge our solutions to our test set, and make some minor adjustments to column names to ensure consistency. \n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Reading in the data using pandas. Join the solutions onto the test set\ntrain_py = pd.read_csv(\"train.csv\")\nsols = pd.read_csv(\"solution.csv\")\ntest_py = pd.read_csv(\"test.csv\")\n\ntest_py = pd.merge(test_py, sols, on=\"id\", suffixes=(\"\", \"_actual\"))\n# Dropping the initial index column, renaming TA1 to a more appropriate format\ntest_py = test_py.drop(test_py.columns[0], axis=1).rename(columns={\"TA1.x\": \"TA1.x\"})\ntrain_py = train_py.drop([train_py.columns[0], train_py.columns[12]], axis=1).rename(columns={\"TA1.x\": \"TA1\"})\n\n# We will be clearing our environment consistently using the del function in python, just to stay organized and clear up space\ndel(sols)\n```\n:::\n\n\nLets plot the data to get a feel for where off the California coast the samples were collected. We're going to use the cartopy package:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# First, we set up the plot with cartopy\nfig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree()) # specifying the map projection we want to use\n\n# Next, we'll define the region of interest (California coast)\nlat_min, lat_max = 30, 37\nlon_min, lon_max = -130, -114\n\n# Set the plot extent (latitude and longitude range of the coast)\nax.set_extent([lon_min, lon_max, lat_min, lat_max])\n\n# Add higher resolution coastlines, land, and ocean features for aesthetics\nax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor=cfeature.COLORS['land']))\nax.add_feature(cfeature.NaturalEarthFeature('physical', 'ocean', '10m', edgecolor='face', facecolor=cfeature.COLORS['water'], alpha = 0.5))\nax.coastlines(resolution='10m')\n\n# Add the borders of the coastline\nax.add_feature(cfeature.BORDERS, linestyle=':')\n\n# Plot the sampling points \nax.scatter(train_py['Lon_Dec'], train_py['Lat_Dec'], color='red', marker='o')\n\n# Add labels and title\nax.set_xticks(np.arange(lon_min, lon_max + 1, 2), crs=ccrs.PlateCarree())\nax.set_yticks(np.arange(lat_min, lat_max + 1, 2), crs=ccrs.PlateCarree())\nax.xaxis.set_major_formatter(LongitudeFormatter())\nax.yaxis.set_major_formatter(LatitudeFormatter())\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(\"CalCOFI Sampling Points along the California Coast\")\n\nplt.show()\n\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n### R\n\nWe read in the data the same way in R. We use an inner_join to bind the test values to the dataframe, and filter out the columns that we're not interested in.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in the solutions data\nsolutions <- read_csv(\"solution.csv\")\n# Read in the testing data, join it to our solutions dataframe. \ntesting <- read_csv(\"test.csv\") |> inner_join(solutions, by = \"id\", suffix = c(\"\", \"_actual\")) |> select(-1, TA1.x = TA1)\n\n# Read in the training data, getting rid of the redundant id column and the other blank column\ntraining <- read_csv(\"train.csv\") |> select(-1, -...13)\n\n# Using doParallel to specify the number of cores that we want to use for some of our more computationally intensive models.  We'll come back to this later\nn_cores <- detectCores() - 1 \n\n# Clearing our environment\nrm(solutions)\n```\n:::\n\n\nWe can also plot the data in R, instead using leaflet to add some basic interactivity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a color palette for DIC. This adds another dimension to the data, and we'll be able to clearly see if there is any sort of spatial pattern with DIC\ncolor_palette <- colorNumeric(palette = \"YlOrRd\", domain = training$DIC)\n\n# Create the leaflet map\nleaflet(training) %>%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"Satellite\") %>%\n  addProviderTiles(\"OpenStreetMap\", group = \"Street Map\") %>%\n  addCircleMarkers(lng = ~Lon_Dec, lat = ~Lat_Dec,\n                   fillColor = ~color_palette(DIC),\n                   fillOpacity = 1, stroke = FALSE,\n                   radius = 3, group = \"Data\") %>%\n  addLegend(pal = color_palette, values = ~DIC,\n            title = \"DIC\", position = \"bottomright\") %>%\n  addLayersControl(baseGroups = c(\"Satellite\", \"Street Map\"),\n                   overlayGroups = \"Data\",\n                   options = layersControlOptions(collapsed = FALSE))\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"leaflet html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-f364e56e9ff613b37e97\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f364e56e9ff613b37e97\">{\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addProviderTiles\",\"args\":[\"Esri.WorldImagery\",null,\"Satellite\",{\"errorTileUrl\":\"\",\"noWrap\":false,\"detectRetina\":false}]},{\"method\":\"addProviderTiles\",\"args\":[\"OpenStreetMap\",null,\"Street Map\",{\"errorTileUrl\":\"\",\"noWrap\":false,\"detectRetina\":false}]},{\"method\":\"addCircleMarkers\",\"args\":[[34.38503,31.418333,34.38503,33.48258,31.41432,32.845,33.41763,34.27143,33.48453,33.1494,32.65432,33.41763,31.428333,34.315,33.418333,32.92,31.41,33.48412,33.81027,34.31638,34.32,32.84633,33.48213,33.488333,33.48412,31.42703,32.65318,33.488333,31.4145,32.416667,33.418333,32.41513,34.31638,33.421667,31.418333,33.8223,33.821667,33.478333,34.49023,34.31582,32.84772,34.2324,34.15253,33.41763,34.28,33.82042,34.276667,34.31638,33.48392,34.275,33.49017,32.416667,33.48228,33,33.42067,32.65397,33.418333,32.92,34.32,34.27143,32.846666,33.42,34.318333,33.14778,33.478333,32.65,34.288333,33.8223,33.41782,34.31638,33.14967,33.41763,34.27,31.4174,31.41382,33.14198,32.92,34.32,34.31487,33.485,32.92,34.321666,34.28082,34.2324,32.646667,33.8221,34.31628,34.275,32.418333,32.846667,34.32,33.41947,34.27192,34.31327,33.14857,31.416667,34.28,34.44992,33.49167,31.415,34.275,34.3165,34.49023,33.48392,32.65133,31.418333,32.421667,33.485,31.41382,33.81027,32.85,33.417,32.8483,33.1494,32.845,34.2749,32.84348,33.42,32.65432,33.48168,32.848333,31.415,34.276667,31.41432,33.41783,33.82,34.27822,32.66247,34.275,33.82253,31.418333,33.488333,31.41283,33.82297,33.48213,32.848333,33.418333,33.49167,34.268333,32.65458,31.41,34.15052,33.82523,32.985,33.42318,32.65318,32.991667,33.483333,34.281667,31.418333,33.41947,32.65133,33.81657,34.16203,32.84562,34.2769,33.823333,33.81027,33.42,32.6524,33.418333,33.483333,34.318333,31.42703,32.413333,33.49017,31.41,33,34.14528,33.14778,31.985,34.315,34.2749,32.843333,31.4174,33.48258,34.16203,32.41752,33.818333,33.14967,33.82337,33.827,33.488333,33.82,34.15207,34.66333,31.41838,32.92,32.915,32.84228,32.84762,33.41947,31.41803,34.31877,33.49167,34.278333,33.41947,34.275,33.82337,31.428333,34.2749,32.843333,34.27143,33.418333,34.27822,33.493333,33.417,33.418333,34.15047,33.14198,32.64917,33.821667,33.82297,34.316667,32.84588,33.493333,34.49023,33.8221,34.275,33.48228,31.41283,31.433333,33.47985,33.418333,34.276666,33.48453,33.823333,34.2324,33.42,33.418333,32.418333,32.845,32.84772,33.488333,34.276667,32.66247,32.848333,33.473333,33.48228,32.82037,31.416667,32.84,32.64917,33.42067,34.288333,33.82,34.31582,32.848333,34.31487,34.32,34.275,32.84,31.41432,32.8451,33.5,34.318333,33.821666,32.846666,32.411667,32.84617,34.31638,32.41813,33.97237,33.82293,34.38503,34.278333,32.843333,33.41787,33.818333,33.41782,34.276666,31.41507,31.41283,33.49017,31.41838,33.418333,33.81657,33.81027,33.48213,33.48213,32.41808,32.65012,32.846666,33.81882,32.845,32.99,33.82407,32.848333,32.41813,33.813333,32.65458,34.15052,32.415,32.41513,32.92,32.65012,32.84762,32.8483,31.991666,31.41838,33.821667,33.97237,34.275,34.27582,32.846666,32.99,34.275,33.41787,32.41808,34.316666,34.32035,34.44958,32.65,32.65318,33.823333,33.82361,32.846666,32.41082,34.3165,34.45118,32.81493,33.82523,31.418333,32.81872,32.81493,32.41813,34.2724,32.65318,31.42703,34.31327,31.42703,34.276667,34.268333,31.41803,33.48228,34.27192,33.97237,34.27427,31.41507,33.488333,33.48392,34.318333,34.31582,31.4174,31.4183,33,32.64837,32.65,32.848333,34.2769,32.41808,33.48453,32.915,32.65068,31.415,33.48453,31.41838,33.488333,32.65133,32.81872,31.988333,32.986666,34.28,32.66247,31.42703,31.416667,34.316667,33.486667,33.41733,32.81403,34.15207,34.27407,32.65432,33.486667,32.41982,33.48228,32.81672,34.44992,34.31327,33.1494,31.415,33.493333,32.848333,33.81555,34.321666,33.41947,34.32,32.92,33.485,34.44932,32.81403,33.48213,33.493333,34.44952,31.4145,34.321666,33.82228,32.846667,32.84348,33.41947,34.16203,34.16203,34.316666,33.48453,32.41778,33.828333,34.315,33.48168,33.488333,33.41783,32.84663,32.65012,32.84617,34.31877,34.316667,33.41783,33.48453,32.84633,32.646667,34.321666,32.65458,33.488333,34.2769,33.81657,33.488333,33.82361,32.8483,32.65458,32.65397,31.418333,31.41382,32.65458,32.92,34.281667,33.42173,34.295,32.84348,32.41808,32.41787,32.985,34.28082,34.3165,34.27407,32.65068,33.48258,32.81672,34.2775,34.15052,32.41513,34.32,34.15052,34.27407,32.653333,34.32,33.42117,33.418333,33.418333,33.488333,33.82293,32.92,34.321666,33.488333,32.84588,33.81555,34.32035,32.82037,34.2324,34.2749,34.3165,33.473333,34.31582,33.82337,34.27143,34.31487,33.82217,33.48258,33.81882,31.416667,32.81952,32.845,32.6524,34.2324,34.31628,34.15047,32.92,31.4145,33.418333,32.418333,34.2749,33.42067,34.14528,32.985,34.278333,31.428333,34.31877,32.85,34.275,34.27143,32.65432,33.97237,33.821667,33.42,33.18017,33.823333,32.41967,30.4175,34.276667,34.2769,34.268333,32.646667,34.27192,33.15023,32.01,33.41308,31.99,32.65068,32.65133,33.485,32.415,33.48213,34.316666,34.31877,34.27822,33.48168,32.418333,34.32035,33.418333,31.428333,33.82337,34.2775,33.48412,34.44812,33.478333,33.97237,33.821667,33.828333,33.14778,33.483333,32.418333,33.41782,32.84633,32.99,32.915,33.82361,31.416667,34.31487,31.41,33.42173,34.2775,32.84762,33.82361,31.41567,32.65117,34.45118,32.843333,34.32,32.65,31.418333,33.42173,33.81555,33.813333,32.84348,33.18017,32.99,33.82337,34.276667,32.41777,34.14528,31.418333,32.411667,34.315,31.41567,32.991667,32.81672,34.27427,33.41763,33.823333,34.14528,32.42103,32.65117,31.4183,32.848333,34.315,32.81672,33.82217,34.275,33.41733,34.27822,32.41752,32.41777,32.95532,33.41782,34.31628,32.986666,31.433333,34.14528,32.66247,34.2749,33.823333,34.2324,33.82,32.418333,34.15052,32.41808,34.276666,31.41507,32.41967,33.81555,34.44958,33.417,33.488333,33.488333,33.82042,31.433333,33.478333,34.31327,32.8483,32.84588,33.48412,34.15317,33.47,34.44992,32.41982,33.42173,33.828333,34.15317,32.41513,32.81493,32.843333,34.15207,33.82,32.81952,33.485,32.915,33.418333,33.828333,34.318333,34.31582,31.418333,34.27427,32.81403,33.488333,33.48223,34.268333,33.82337,32.65,32.41513,33.823333,32.843333,34.15047,31.416667,33.418333,34.32,33.421667,33.48392,32.411667,32.846666,34.318333,32.41082,32.848333,34.49023,34.27427,33.82,31.088333,33.821666,33.48228,34.316667,32.84663,32.82037,32.81672,31.988333,31.428333,34.295,31.99,33.418333,33.821667,34.316666,33.483333,32.01,32.418333,33.823333,33.48392,33.418333,32.415,34.16203,33.14857,33.418333,33.41783,33.42067,32.65117,33.41308,33.49167,34.15253,34.316667,33.823333,32.915,32.846667,34.38503,32.81952,31.41382,33.82,34.275,34.45118,32.418333,34.27407,34.49023,33.42,32.85,32.41967,34.31582,33.47985,33.823333,32.418333,33.82407,32.41813,32.411667,33.418333,34.27582,33.821666,34.38503,32.84228,32.913333,33.821666,32.421667,32.99,33.823333,32.81403,34.32,34.2775,33.8895,33.42318,33.41782,32.8451,32.42103,33.82042,32.843333,32.848333,33.82,33.82253,34.271667,32.416667,33.14198,33.82337,33.82217,33.14857,33.81657,33.1494,34.146667,32.845,31.41432,32.84588,32.65012,34.44952,34.295,33.823333,34.318333,33.418333,32.8483,32.65117,32.81403,33.49167,33.15023,34.318333,32.84663,33.813333,34.315,34.32,31.4183,31.41283,33.493333,31.416667,34.275,33.81027,34.31912,33.488333,32.416667,33.821667,34.276666,32.84562,34.15253,33.48223,34.275,32.82,33.8223,34.15052,32.65458,34.278333,32.991667,34.316667,33.488333,34.146667,33.821666,34.31912,33.48223,34.2324,32.66247,34.27,32.985,34.31638,33.82253,32.8483,34.32035,33.8221,34.295,31.41,33.41308,31.41382,31.991666,34.2724,33.418333,34.278333,34.27822,32.92,34.14528,31.4171,34.38503,32.84588,33.82042,33.823333,33.82293,33.818333,33.823333,34.32,34.32,31.991666,32.81952,33.82253,32.913333,33.82297,32.65068,32.41797,32.84,33.42318,32.646667,33.48258,34.32,32.65068,32.846666,33.82523,33.48223,34.32,34.295,33.493333,34.2749,34.15047,32.415,32.41777,34.275,34.31912,33.82217,32.65,32.41813,34.2724,34.27582,31.418333,33.48453,32.64837,31.41,31.428333,34.44992,33.82297,31.41283,34.31487,34.15047,32.66247,34.275,34.27582,32.84562,32.41082,34.315,33.42,32.418333,31.418333,33.82253,31.41507,33.483333,34.15253,34.27143,32.6524,32.81493,32.84348,34.276667,31.988333,34.146667,34.44812,34.2749,33.42,32.41752,34.44812,34.146667,32.84562,33.48213,32.01,31.4183,32.41797,34.31487,33.823333,33.478333,33.48223,32.41787,33.47985,34.2775,33.47985,32.41967,34.31628,33.823333,33.41763,34.31628,34.275,33.48412,33.823333,32.84762,31.4145,31.41803,31.99,31.415,31.418333,32.82037,34.2724,33.41733,32.81952,34.49023,33.8223,34.275,31.41432,34.268333,32.81872,31.41382,33.82228,32.01,34.315,32.41082,31.991666,34.31877,33.823333,32.418333,34.32,33.14967,32.843333,32.41797,33.813333,32.65133,31.985,34.31487,33.48168,34.27582,32.985,32.65133,33.47985,34.31877,31.99,34.31877,34.27192,34.27192,31.433333,34.31912,31.985,32.41082,34.275,33.42117,32.416667,34.315,32.42103,33.821667,31.41507,33.48453,33.8221,33.417,33.82361,33.48392,32.65012,32.986666,32.84348,33.821666,34.31628,32.81952,31.415,33.41782,32.415,33.143333,33.421667,32.848333,32.82037,32.81403,32.92,34.316667,34.2324,32.41982,34.316666,31.428333,33.48223,32.84772,31.991666,34.16203,34.276667,32.986666,32.843333,32.41752,32.413333,33.82253,33.82407,32.84348,33.82361,31.4145,32.84762,33.42,31.4183,32.843333,33.82,34.275,34.315,32.8451,33.1494,32.81952,34.14528,31.41432,33.823333,30.4175,34.32,33.42117,32.64837,33.491667,32.41967,34.3165,32.84588,33.1494,32.8483,32.64837,32.991667,34.271667,32.65133,32.41797,34.14528,33.48412,33.8221,33.485,32.41513,33.823333,33.82297,32.84,34.315,32.41787,33.42067,33.48168,32.84228,32.84663,32.418333,34.66333,33.41783,33.418333,32.65068,32.84663,33.14857,34.32035,33.49017,34.321666,31.985,33.821666,32.6524,31.41,34.31638,34.15047,33.48258,33.82,31.41567,34.31327,31.42703,32.41787,34.288333,32.65068,32.846667,33.418333,33.41787,34.66333,33.48168,33.81555,32.848333,32.415,32.41778,32.646667,34.27143,32.81493,33.82042,32.01,34.44932,33.418333,33,31.41283,32.84588,33.478333,32.415,32.845,33.48223,33.97237,33.823333,34.27427,32.843333,33.418333,34.32,33.48168,34.31912,34.49023,33.41947,33.8223,32.415,33.48258,32.413333,34.15253,33.48213,32.846667,34.3165,31.991666,32.41777,33.48223,34.311667,34.31327,33.491667,33.81882,34.32,33.82407,32.84762,33.1494,32.41082,32.84617,32.92,33.8221,34.316667,34.276666,33.47985,33.41787,34.318333,33.82297,32.41982,33.42,34.275,32.64837,32.84,31.41,34.66333,31.433333,31.418333,34.281667,34.31877,33.41787,31.418333,32.41778,32.65397,33.41763,33.82042,34.27822,33.485,33.827,32.84617,31.41,33.485,32.41808,33.42,34.276666,32.421667,32.85,31.41803,34.15317,32.65133,33.48392,33.417,31.4183,34.27192,32.848333,32.84663,34.316667,32.64917,33.41733,34.2769,33.42318,34.275,34.318333,32.64917,31.418333,32.8451,33.821667,32.65318,34.3165,33.823333,32.92,33.82523,32.84617,33.82228,32.41808,33.41308,32.84633,33.82228,32.65,33.486667,32.41813,31.41,33.418333,31.4171,32.41752,33.827,32.84772,34.15207,31.988333,31.4174,32.65432,33.81555,32.416667,31.41382,33.488333,33.82253,34.15047,32.84663,33.82293,34.66333,34.316667,34.316667,33.42318,32.413333,31.4171,34.28082,33.418333,32.41777,32.65,34.28,33.488333,34.27822,32.41813,32.41982,34.315,33.82228,32.41778,32.846666,32.843333,32.846666,33.49017,32.991667,32.843333,32.81672,33.82523,32.65397,32.65012,33.48228,33.823333,33.81555,33.418333,34.316667,33.82293,33.15023,33.42173,33.42173,33.41308,33.823333,32.66247,32.84617,32.846666,33.48767,33.41783,33.82228,31.4171,33.81882,32.81872,32.653333,32.41813,34.44812,32.653333,31.41567,32.41982,34.271667,32.848333,32.90882,32.65432,34.27407,32.65,31.41838,32.92,32.85,33.97237,32.65117,33.82217,33.828333,33.42117,32.82037,34.15253,34.315,31.41,31.42703,34.27822,32.64837,32.84663,33.488333,32.843333,31.41507,32.81403,33.146667,33.48258,34.45118,32.418333,34.2769,33.41763,32.82037,33.82407,34.27192,33.81657,34.28,34.2769,31.985,34.16203,33.82217,34.288333,32.8451,34.31487,32.65397,33.488333,34.27407,34.276667,31.428333,32.985,32.84772,33.418333,32.41797,32.846666,33.418333,33,33.48223,32.42103,33.47985,33.823333,32.41787,31.41507,32.416667,31.416667,34.32,33.493333,34.28082,32.845,33.485,34.311667,33.48767,33.15023,32.81872,32.65,32.66247,34.27,31.4145,34.288333,32.411667,34.15047,34.31327,32.41797,34.1805,31.41567,34.2775,32.65397,32.845,32.84562,32.41787,32.41797,32.41967,31.4174,31.433333,33.42,31.433333,32.41808,34.316667,34.22737,33.82407,31.415,33.81027,34.31912,32.65117,31.428333,32.41778,33.823333,32.92,32.84633,34.15317,32.64917,31.418333,32.843333,34.66333,34.38503,31.428333,31.4145,32.653333,33.48468,33.41733,33.14778,33.82228,32.653333,34.38503,34.66333,33.41782,32.843333,33.488333,34.31877,34.28082,33.14778,34.318333,32.6524,33.821666,32.65318,33.417,31.428333,34.14528,33.493333,31.41803,34.15207,34.27427,34.316667,33.821666,34.268333,34.16203,34.275,34.31638,32.913333,32.81872,32.646667,33.491667,31.4171,33.48228,33.48392,32.421667,32.413333,34.44952,34.27,34.27582,32.418333,32.81872,33.14198,33.485,33.418333,34.28082,31.41432,32.41082,33.82042,33.488333,34.2724,32.84772,34.66333,33.418333,34.27,32.65117,34.28,33.818333,33.82361,32.413333,33.81555,32.8451,34.2324,32.84633,33.42,34.271667,31.41,34.27427,32.42103],[-120.66553,-121.998333,-120.66553,-122.53307,-121.99767,-117.54,-117.9034,-120.02587,-122.53108,-123.22062,-119.48232,-117.9034,-121.993333,-120.813333,-117.898333,-118.938333,-121.991667,-122.53382,-121.84337,-120.80213,-120.79787,-117.5313,-122.53752,-119.323333,-122.53382,-121.97902,-119.47958,-122.533333,-121.99232,-119.956667,-117.898333,-119.96142,-120.80213,-117.915,-121.998333,-121.8382,-118.633333,-122.535,-120.92117,-120.8065,-117.53193,-120.97948,-121.15268,-117.9034,-120.023333,-121.84573,-120.03,-120.80213,-122.53138,-120.02,-122.543,-119.956667,-122.53438,-120.39,-117.90133,-119.48538,-117.908333,-118.938333,-120.79787,-120.02587,-117.528333,-117.9,-120.803333,-123.2202,-122.535,-119.481667,-120.028333,-121.8382,-117.90867,-120.80213,-123.22272,-117.9034,-120.021666,-121.99422,-121.996,-123.2209,-118.938333,-120.79787,-120.804,-122.541667,-118.938333,-120.811666,-120.03182,-120.97948,-119.491667,-118.62953,-120.80113,-120.025,-119.958333,-117.533333,-120.80682,-117.90327,-120.0276,-120.79398,-123.2225,-122.001667,-120.023333,-120.52393,-122.53982,-122.016667,-120.025,-120.8009,-120.92117,-122.53138,-119.48202,-122.001667,-119.96,-122.541667,-121.996,-121.84337,-117.531667,-117.911,-117.52998,-123.22062,-117.536667,-120.02508,-117.53017,-117.9,-119.48232,-122.534,-117.528333,-122.016667,-120.03,-121.99767,-117.90288,-118.626667,-120.02078,-119.48342,-120.033333,-118.62812,-122.001667,-122.551667,-121.99633,-118.62882,-122.53752,-117.528333,-117.905,-122.53982,-120.021667,-119.48298,-121.991667,-121.14713,-118.62683,-120.346666,-117.90352,-119.47958,-120.34,-122.535,-120.038333,-121.998333,-117.90327,-119.48202,-121.8428,-121.15758,-117.53203,-120.02423,-118.63,-121.84337,-117.901667,-119.4811,-117.898333,-122.535,-120.803333,-121.97902,-119.966667,-122.543,-121.991667,-120.39,-120.68388,-123.2202,-122.403333,-120.813333,-120.02508,-117.533333,-121.99422,-122.53307,-121.15758,-119.96252,-118.625,-123.22272,-118.629,-118.63057,-119.323333,-118.626667,-121.15003,-121.0434,-121.99563,-118.938333,-118.945,-117.53622,-117.53343,-117.90327,-121.98997,-120.80207,-122.53982,-120.025,-117.90327,-120.031667,-118.629,-121.981667,-120.02508,-117.533333,-120.02587,-117.901667,-120.02078,-119.313333,-117.911,-117.9,-121.14983,-123.2209,-119.48517,-118.63,-118.62882,-120.811667,-117.53122,-119.313333,-120.92117,-118.62953,-120.033333,-122.53438,-121.99633,-121.986667,-122.53081,-117.908333,-120.025,-122.53108,-118.631667,-120.97948,-117.9,-117.9,-119.968333,-117.536667,-117.53193,-119.323333,-120.03,-119.48342,-117.528333,-122.54,-122.53438,-123.9004,-122.001667,-117.538333,-119.48517,-117.90133,-120.028333,-118.64,-120.8065,-117.53,-120.804,-120.80682,-120.031667,-117.538333,-121.99767,-117.53172,-122.531667,-120.803333,-118.628333,-117.535,-119.971667,-117.533,-120.80213,-119.96012,-120.5707,-118.62723,-120.66553,-120.025,-117.533333,-117.90668,-118.625,-117.90867,-120.025,-121.99767,-121.99633,-122.543,-121.99563,-117.901667,-121.8428,-121.84337,-122.53752,-122.53752,-119.953,-119.4764,-117.535,-118.63067,-117.536667,-120.346666,-118.62738,-117.53,-119.96012,-118.626667,-119.48298,-121.14713,-119.961667,-119.96142,-118.938333,-119.4764,-117.53343,-117.52998,-122.393333,-121.99563,-118.63,-120.5707,-120.031667,-120.02328,-117.535,-120.346666,-120.02,-117.90668,-119.953,-120.803333,-120.79869,-120.52332,-119.481667,-119.47958,-118.631667,-121.84444,-117.535,-119.94582,-120.8009,-120.5247,-123.90738,-118.62683,-122.001667,-123.90777,-123.90738,-119.96012,-120.02573,-119.47958,-121.97902,-120.79398,-121.97902,-120.028333,-120.021667,-121.98997,-122.53438,-120.0276,-120.5707,-120.03057,-121.99767,-122.533333,-122.53138,-120.803333,-120.8065,-121.99422,-121.9898,-120.39,-119.48527,-119.481667,-117.53,-120.02423,-119.953,-122.53108,-118.945,-119.4804,-122.016667,-122.53108,-121.99563,-122.533333,-119.48202,-123.90777,-122.388333,-120.351666,-120.023333,-119.48342,-121.97902,-122.001667,-120.811667,-119.323333,-117.90578,-123.90517,-121.15003,-120.02473,-119.48232,-119.323333,-119.9655,-122.53438,-123.9064,-120.52393,-120.79398,-123.22062,-122.016667,-119.313333,-117.53,-121.84499,-120.811666,-117.90327,-120.79787,-118.938333,-122.536667,-120.52307,-123.90517,-122.53752,-119.313333,-120.52363,-121.99232,-120.811666,-118.62652,-117.533333,-117.53017,-117.90327,-121.15758,-121.15758,-120.803333,-122.53108,-119.95873,-118.625,-120.813333,-122.534,-122.551667,-117.90288,-117.5315,-119.4764,-117.533,-120.80207,-120.805,-117.90288,-122.53108,-117.5313,-119.491667,-120.811666,-119.48298,-122.533333,-120.02423,-121.8428,-122.533333,-121.84444,-117.52998,-119.48298,-119.48538,-122.001667,-121.996,-119.48298,-118.938333,-120.038333,-117.90127,-120.831666,-117.53017,-119.953,-119.9594,-120.346666,-120.03182,-120.8009,-120.02473,-119.4804,-122.53307,-123.9064,-120.05032,-121.14713,-119.96142,-120.798333,-121.14713,-120.02473,-119.486667,-120.80682,-117.9052,-117.901667,-117.908333,-122.551667,-118.62723,-118.935,-120.811666,-119.323333,-117.53122,-121.84499,-120.79869,-123.9004,-120.97948,-120.02508,-120.8009,-122.54,-120.8065,-118.629,-120.02587,-120.804,-118.626,-122.53307,-118.63067,-122.001667,-123.90973,-117.54,-119.4811,-120.97948,-120.80113,-121.14983,-118.938333,-121.99232,-117.908333,-119.968333,-120.02508,-117.90133,-120.68388,-120.346666,-120.025,-121.981667,-120.80207,-117.531667,-120.025,-120.02587,-119.48232,-120.5707,-118.63,-117.901667,-118.39332,-118.626667,-119.95228,-124.00067,-120.03,-120.02423,-120.021667,-119.491667,-120.0276,-123.22093,-122.393333,-117.90933,-122.393333,-119.4804,-119.48202,-122.541667,-119.961667,-122.53752,-120.803333,-120.80207,-120.02078,-122.534,-119.958333,-120.79869,-117.908333,-121.981667,-118.629,-120.05032,-122.53382,-120.5254,-122.535,-120.5707,-118.63,-118.625,-123.2202,-122.535,-119.968333,-117.90867,-117.5313,-120.346666,-118.945,-121.84444,-122.001667,-120.804,-121.991667,-117.90127,-120.05032,-117.53343,-121.84444,-121.9852,-119.48417,-120.5247,-117.533333,-120.798333,-119.481667,-122.001667,-117.90127,-121.84499,-118.626667,-117.53017,-118.39332,-120.346666,-118.629,-120.03,-119.95838,-120.68388,-121.998333,-119.971667,-120.813333,-121.9852,-120.34,-123.9064,-120.03057,-117.9034,-118.626667,-120.68388,-119.96358,-119.48417,-121.9898,-117.531667,-120.798333,-123.9064,-118.626,-120.02,-117.90578,-120.02078,-119.96252,-119.95838,-117.3086,-117.90867,-120.80113,-120.351666,-121.986667,-120.68388,-119.48342,-120.02508,-118.63,-120.97948,-118.64,-119.958333,-121.14713,-119.953,-120.025,-121.99767,-119.95228,-121.84499,-120.52332,-117.911,-122.551667,-119.323333,-121.84573,-121.986667,-122.535,-120.79398,-117.52998,-117.53122,-122.53382,-121.14933,-122.495,-120.52393,-119.9655,-117.90127,-118.625,-121.14933,-119.96142,-123.90738,-117.531667,-121.15003,-118.626667,-123.90973,-122.541667,-118.945,-117.905,-118.625,-120.8,-120.8065,-121.998333,-120.03057,-123.90517,-119.323333,-122.53563,-120.021667,-118.629,-119.475,-119.96142,-118.631667,-117.533333,-121.14983,-122.001667,-117.9,-120.80682,-117.915,-122.53138,-119.971667,-117.535,-120.8,-119.94582,-117.531667,-120.92117,-120.03057,-118.64,-122.663333,-118.628333,-122.53438,-120.805,-117.5315,-123.9004,-123.9064,-122.388333,-121.981667,-120.831666,-122.393333,-117.901667,-118.633333,-120.803333,-122.535,-122.393333,-119.968333,-118.63,-122.53138,-117.908333,-119.95,-121.15758,-123.2225,-117.905,-117.90288,-117.90133,-119.48417,-117.90933,-122.53982,-121.15268,-120.811667,-118.626667,-118.945,-117.533333,-120.66553,-123.90973,-121.996,-118.626667,-120.025,-120.5247,-119.958333,-120.02473,-120.92117,-117.9,-117.531667,-119.95228,-120.8065,-122.53081,-118.628333,-119.958333,-118.62738,-119.96012,-119.971667,-117.908333,-120.02328,-118.628333,-120.66553,-117.53622,-118.926667,-118.628333,-119.96,-120.346666,-118.63,-123.90517,-120.798333,-120.05032,-118.4925,-117.90352,-117.90867,-117.53172,-119.96358,-121.84573,-117.533333,-117.531667,-118.626667,-118.62812,-120.023333,-119.956667,-123.2209,-118.629,-118.626,-123.2225,-121.8428,-123.22062,-121.143333,-117.54,-121.99767,-117.53122,-119.4764,-120.52363,-120.831666,-118.63,-120.803333,-117.905,-117.52998,-119.48417,-123.90517,-122.53982,-123.22093,-120.803333,-117.5315,-118.626667,-120.813333,-120.79787,-121.9898,-121.99633,-119.316666,-122.001667,-120.031667,-121.84337,-120.80587,-122.533333,-119.965,-118.63,-120.025,-117.53203,-121.15268,-122.53563,-120.025,-123.9,-121.8382,-121.14713,-119.48298,-120.025,-120.34,-120.811667,-122.551667,-121.143333,-118.628333,-120.80587,-122.53563,-120.97948,-119.48342,-120.021666,-120.346666,-120.80213,-118.62812,-117.52998,-120.79869,-118.62953,-120.831666,-121.991667,-117.90933,-121.996,-122.393333,-120.02573,-117.901667,-120.025,-120.02078,-118.935,-120.68388,-121.98952,-120.66553,-117.53122,-121.84573,-118.63,-118.62723,-118.625,-118.628333,-120.80682,-120.79787,-122.393333,-123.90973,-118.62812,-118.926667,-118.62882,-119.4804,-119.9588,-117.538333,-117.90352,-119.491667,-122.53307,-120.798333,-119.4804,-117.528333,-118.62683,-122.53563,-120.80682,-120.831666,-119.316666,-120.02508,-121.14983,-119.95,-119.95838,-120.033333,-120.80587,-118.626,-119.475,-119.96012,-120.02573,-120.02328,-121.998333,-122.53108,-119.48527,-121.991667,-121.993333,-120.52393,-118.62882,-121.99633,-120.804,-121.14983,-119.48342,-120.02,-120.02328,-117.53203,-119.94582,-120.813333,-117.901667,-119.958333,-122.001667,-118.62812,-121.99767,-122.535,-121.15268,-120.02587,-119.4811,-123.90738,-117.53017,-120.03,-122.388333,-121.143333,-120.5254,-120.02508,-117.9,-119.96252,-120.5254,-121.143333,-117.53203,-122.53752,-122.393333,-121.9898,-119.9588,-120.804,-118.631667,-122.535,-122.53563,-119.9594,-122.53081,-120.05032,-122.53081,-119.95228,-120.80113,-118.628333,-117.9034,-120.80113,-120.031667,-122.53382,-118.631667,-117.53343,-121.99232,-121.98997,-122.393333,-122.016667,-121.998333,-123.9004,-120.02573,-117.90578,-123.90973,-120.92117,-121.8382,-120.025,-121.99767,-120.021667,-123.90777,-121.996,-118.62652,-122.393333,-120.798333,-119.94582,-122.393333,-120.80207,-118.631667,-119.968333,-120.798333,-123.22272,-117.531667,-119.9588,-118.626667,-119.48202,-122.403333,-120.804,-122.534,-120.02328,-120.346666,-119.48202,-122.53081,-120.80207,-122.393333,-120.80207,-120.0276,-120.0276,-121.986667,-120.80587,-122.403333,-119.94582,-120.033333,-117.9052,-119.965,-120.798333,-119.96358,-118.633333,-121.99767,-122.53108,-118.62953,-117.911,-121.84444,-122.53138,-119.4764,-120.351666,-117.53017,-118.628333,-120.80113,-123.90973,-122.016667,-117.90867,-119.961667,-123.226667,-117.915,-117.531667,-123.9004,-123.90517,-118.935,-120.811667,-120.97948,-119.9655,-120.803333,-121.993333,-122.53563,-117.53193,-122.393333,-121.15758,-120.028333,-120.351666,-117.533333,-119.96252,-119.966667,-118.62812,-118.62738,-117.53017,-121.84444,-121.99232,-117.53343,-117.901667,-121.9898,-117.531667,-118.626667,-120.025,-120.813333,-117.53172,-123.22062,-123.90973,-120.68388,-121.99767,-118.63,-124.00067,-120.79787,-117.9052,-119.48527,-122.533333,-119.95228,-120.8009,-117.53122,-123.22062,-117.52998,-119.48527,-120.34,-120.023333,-119.48202,-119.9588,-120.68388,-122.53382,-118.62953,-122.541667,-119.96142,-118.63,-118.62882,-117.538333,-120.798333,-119.9594,-117.90133,-122.534,-117.53622,-117.5315,-119.958333,-121.0434,-117.90288,-117.901667,-119.4804,-117.5315,-123.2225,-120.79869,-122.543,-120.811666,-122.403333,-118.628333,-119.4811,-121.991667,-120.80213,-121.14983,-122.53307,-118.64,-121.9852,-120.79398,-121.97902,-119.9594,-120.028333,-119.4804,-117.533333,-117.905,-117.90668,-121.0434,-122.534,-121.84499,-117.53,-119.961667,-119.95873,-119.491667,-120.02587,-123.90738,-121.84573,-122.393333,-120.52307,-117.908333,-120.39,-121.99633,-117.53122,-122.535,-119.95,-117.536667,-122.53563,-120.5707,-118.63,-120.03057,-117.533333,-117.905,-120.798333,-122.534,-120.80587,-120.92117,-117.90327,-121.8382,-119.95,-122.53307,-119.966667,-121.15268,-122.53752,-117.533333,-120.8009,-122.393333,-119.95838,-122.53563,-120.818333,-120.79398,-122.533333,-118.63067,-120.80682,-118.62738,-117.53343,-123.22062,-119.94582,-117.533,-118.935,-118.62953,-120.805,-120.025,-122.53081,-117.90668,-120.8,-118.62882,-119.9655,-117.901667,-120.025,-119.48527,-117.538333,-121.991667,-121.0434,-121.986667,-122.001667,-120.038333,-120.80207,-117.90668,-121.998333,-119.95873,-119.48538,-117.9034,-121.84573,-120.02078,-122.541667,-118.63057,-117.533,-121.991667,-122.541667,-119.953,-117.901667,-120.025,-119.96,-117.531667,-121.98997,-121.14933,-119.48202,-122.53138,-117.911,-121.9898,-120.0276,-117.53,-117.5315,-120.805,-119.48517,-117.90578,-120.02423,-117.90352,-120.031667,-120.803333,-119.48517,-122.001667,-117.53172,-118.63,-119.47958,-120.8009,-118.626667,-118.938333,-118.62683,-117.533,-118.62652,-119.953,-117.90933,-117.5313,-118.62652,-119.481667,-119.323333,-119.96012,-121.991667,-117.898333,-121.98952,-119.96252,-118.63057,-117.53193,-121.15003,-122.388333,-121.99422,-119.48232,-121.84499,-119.965,-121.996,-119.323333,-118.62812,-121.14983,-117.5315,-118.62723,-121.0434,-120.811667,-120.805,-117.90352,-119.966667,-121.98952,-120.03182,-117.908333,-119.95838,-119.481667,-120.023333,-122.551667,-120.02078,-119.96012,-119.9655,-120.798333,-118.62652,-119.95873,-117.528333,-117.533333,-117.528333,-122.543,-120.34,-117.533333,-123.9064,-118.62683,-119.48538,-119.4764,-122.53438,-118.628333,-121.84499,-117.9,-120.811667,-118.62723,-123.22093,-117.90127,-117.90127,-117.90933,-118.63,-119.48342,-117.533,-117.528333,-117.76867,-117.90288,-118.62652,-121.98952,-118.63067,-123.90777,-119.486667,-119.96012,-120.5254,-119.486667,-121.9852,-119.9655,-120.023333,-117.53,-117.39082,-119.48232,-120.02473,-119.475,-121.99563,-118.938333,-117.531667,-120.5707,-119.48417,-118.626,-118.625,-117.9052,-123.9004,-121.15268,-120.798333,-121.991667,-121.97902,-120.02078,-119.48527,-117.5315,-119.323333,-117.533333,-121.99767,-123.90517,-123.223333,-122.53307,-120.5247,-119.968333,-120.02423,-117.9034,-123.9004,-118.62738,-120.0276,-121.8428,-120.023333,-120.02423,-122.403333,-121.15758,-118.626,-120.028333,-117.53172,-120.804,-119.48538,-119.323333,-120.02473,-120.03,-121.981667,-120.346666,-117.53193,-117.898333,-119.9588,-117.528333,-117.9,-120.39,-122.53563,-119.96358,-122.53081,-118.626667,-119.9594,-121.99767,-119.956667,-122.001667,-120.80682,-119.313333,-120.03182,-117.54,-122.541667,-120.818333,-117.76867,-123.22093,-123.90777,-119.481667,-119.48342,-120.021666,-121.99232,-120.028333,-119.971667,-121.14983,-120.79398,-119.9588,-119.51062,-121.9852,-120.05032,-119.48538,-117.54,-117.53203,-119.9594,-119.9588,-119.95228,-121.99422,-121.986667,-117.9,-121.986667,-119.953,-120.805,-119.4099,-118.62738,-122.016667,-121.84337,-120.80587,-119.48417,-121.981667,-119.95873,-118.628333,-118.938333,-117.5313,-121.14933,-119.48517,-121.998333,-117.531667,-121.0434,-120.66553,-121.981667,-121.99232,-119.486667,-117.7669,-117.90578,-123.2202,-118.62652,-119.486667,-120.66553,-121.0434,-117.90867,-117.531667,-119.323333,-120.80207,-120.03182,-123.2202,-120.8,-119.4811,-118.628333,-119.47958,-117.911,-121.981667,-120.68388,-119.313333,-121.98997,-121.15003,-120.03057,-120.805,-118.628333,-120.021667,-121.15758,-120.033333,-120.80213,-118.926667,-123.90777,-119.491667,-122.533333,-121.98952,-122.53438,-122.53138,-119.96,-119.966667,-120.52363,-120.021666,-120.02328,-119.968333,-123.90777,-123.2209,-122.536667,-117.898333,-120.03182,-121.99767,-119.94582,-121.84573,-119.323333,-120.02573,-117.53193,-121.0434,-117.908333,-120.021666,-119.48417,-120.023333,-118.625,-121.84444,-119.966667,-121.84499,-117.53172,-120.97948,-117.5313,-117.901667,-120.023333,-121.991667,-120.03057,-119.96358],3,null,\"Data\",{\"interactive\":true,\"className\":\"\",\"stroke\":false,\"color\":\"#03F\",\"weight\":5,\"opacity\":0.5,\"fill\":true,\"fillColor\":[\"#DE171E\",\"#E7261E\",\"#FEAF4A\",\"#F64426\",\"#E8281F\",\"#FEDA79\",\"#BE0126\",\"#FFF0A7\",\"#E6241E\",\"#FD8D3C\",\"#FFE289\",\"#EC3021\",\"#FFE897\",\"#FEA647\",\"#E6241E\",\"#FFE999\",\"#FFEC9F\",\"#FFEFA5\",\"#E2191C\",\"#FFEB9B\",\"#ED3321\",\"#E5201D\",\"#FEDB7A\",\"#D9141F\",\"#FED470\",\"#FD6D32\",\"#FFEC9E\",\"#FEB14C\",\"#FD8639\",\"#EE3422\",\"#BF0226\",\"#FFE997\",\"#FD5B2D\",\"#860026\",\"#FFEEA3\",\"#F33F25\",\"#BB0026\",\"#FFEA9A\",\"#FD7434\",\"#EE3622\",\"#FC4F2A\",\"#DE171E\",\"#FFE997\",\"#FED673\",\"#E1191D\",\"#EC3121\",\"#A40026\",\"#F33F25\",\"#ED3321\",\"#EF3823\",\"#FD7C36\",\"#FD8E3C\",\"#FB4D2A\",\"#FED06C\",\"#FFE896\",\"#EC3021\",\"#FEB650\",\"#FFEEA2\",\"#FE9C42\",\"#FA4A29\",\"#FC592C\",\"#FFEEA2\",\"#DA151F\",\"#DD171E\",\"#FEAF4B\",\"#FFEA9A\",\"#FFDE80\",\"#B80026\",\"#EE3622\",\"#FFF0A6\",\"#B60026\",\"#FFEDA1\",\"#FEAF4B\",\"#FD8F3D\",\"#FFE998\",\"#BE0126\",\"#FD602E\",\"#FA4A29\",\"#FFE999\",\"#E0181D\",\"#E5201D\",\"#FD5A2D\",\"#FD6D32\",\"#F54226\",\"#E6231E\",\"#FEA245\",\"#FA4A29\",\"#FFCC69\",\"#EF3622\",\"#FFC05B\",\"#DB161F\",\"#FED16D\",\"#FFDF83\",\"#FC552C\",\"#C20325\",\"#FB4D2A\",\"#FFE188\",\"#FEA044\",\"#FFE794\",\"#FFEA99\",\"#F64326\",\"#FFCC67\",\"#F33E25\",\"#B80026\",\"#F84828\",\"#EC3121\",\"#FEAC49\",\"#FFEEA3\",\"#E5201D\",\"#FFEA99\",\"#FB4D2A\",\"#F13A23\",\"#C30425\",\"#FFEEA1\",\"#EA2C20\",\"#FC4E2A\",\"#FFE58F\",\"#FD9640\",\"#FE9E43\",\"#DA151F\",\"#FD8B3B\",\"#BA0026\",\"#FC512B\",\"#FEA044\",\"#C50624\",\"#FEA044\",\"#FD7C36\",\"#FA4A29\",\"#FFF4B2\",\"#FD8A3B\",\"#BD0026\",\"#DB151F\",\"#FFE896\",\"#FEB852\",\"#EF3823\",\"#DA151F\",\"#F23E25\",\"#FEA245\",\"#9E0026\",\"#DE171E\",\"#FEB14C\",\"#FD943F\",\"#EE3522\",\"#B70026\",\"#CD0C22\",\"#FEAF4B\",\"#FED874\",\"#FFEEA2\",\"#FFF7B9\",\"#FFEEA2\",\"#BA0026\",\"#FFE187\",\"#F84728\",\"#BE0026\",\"#FEDC7C\",\"#FEB650\",\"#C20425\",\"#FFEA9B\",\"#F94A29\",\"#FD602E\",\"#FE9C42\",\"#E41D1C\",\"#FD7B36\",\"#FFEB9D\",\"#FD7735\",\"#FFBD58\",\"#FD923E\",\"#FFEDA0\",\"#FFE48E\",\"#FD652F\",\"#FFEEA2\",\"#E1191D\",\"#9F0026\",\"#EA2C20\",\"#FFEFA5\",\"#BD0026\",\"#FFE691\",\"#FFEA9A\",\"#FD8037\",\"#FB4D2A\",\"#FEA446\",\"#FEAB49\",\"#FD7233\",\"#BE0126\",\"#FC532B\",\"#BF0126\",\"#FE9F43\",\"#C20425\",\"#F44126\",\"#F54226\",\"#FC4E2A\",\"#F44125\",\"#FFED9F\",\"#FFE38A\",\"#B60026\",\"#E7261E\",\"#FD5F2E\",\"#D61220\",\"#FFEB9C\",\"#BD0026\",\"#FFF0A9\",\"#FFE084\",\"#FEB650\",\"#FFE895\",\"#FD883A\",\"#BA0026\",\"#BE0026\",\"#FFEFA5\",\"#FED36F\",\"#FC522B\",\"#BF0126\",\"#F64427\",\"#E5211D\",\"#B80026\",\"#FD6C32\",\"#FFE794\",\"#C00225\",\"#E1191D\",\"#FFE48E\",\"#FE9F44\",\"#BE0126\",\"#FEB14B\",\"#FFE998\",\"#FD873A\",\"#FA4A29\",\"#FFEC9F\",\"#FD8138\",\"#FFC560\",\"#BE0126\",\"#FE9F43\",\"#FFDF83\",\"#FFE895\",\"#FD8439\",\"#D61220\",\"#D9141F\",\"#DD161E\",\"#FFF0A8\",\"#FFE895\",\"#FD7735\",\"#FEBB55\",\"#FFBD58\",\"#FD7F37\",\"#FED470\",\"#C10325\",\"#FE9A41\",\"#FED470\",\"#FD6530\",\"#FFC965\",\"#FFEA99\",\"#EF3622\",\"#FFE188\",\"#E31A1C\",\"#FFEA99\",\"#FEB24C\",\"#FFEEA3\",\"#EB2F20\",\"#FD8138\",\"#FFEB9B\",\"#BA0026\",\"#FC592C\",\"#CE0D22\",\"#FFE895\",\"#FFE48E\",\"#FEA848\",\"#FD8C3C\",\"#FC592D\",\"#F74527\",\"#F74627\",\"#FEAB49\",\"#C00225\",\"#FE9C42\",\"#940026\",\"#FED875\",\"#FFE895\",\"#FFEC9E\",\"#EC3021\",\"#FEA345\",\"#FEA446\",\"#FFE38C\",\"#FFDE81\",\"#FFE895\",\"#D9141F\",\"#C00225\",\"#FEA345\",\"#FD7333\",\"#DE171E\",\"#FEB14C\",\"#FD9640\",\"#FFE997\",\"#FFEA9A\",\"#FFE692\",\"#FFE896\",\"#FFE288\",\"#FFE998\",\"#F23E24\",\"#BD0026\",\"#D10F21\",\"#FFCD69\",\"#FD6D32\",\"#FFEC9F\",\"#EE3522\",\"#FED26F\",\"#FE9841\",\"#FD6D32\",\"#FFC965\",\"#FFEA99\",\"#FFC15C\",\"#FFE58E\",\"#C00225\",\"#E51F1D\",\"#CB0A23\",\"#FD6C31\",\"#B90026\",\"#FD6630\",\"#E92B1F\",\"#FFE38A\",\"#DD171E\",\"#FFE794\",\"#FFEDA0\",\"#FED673\",\"#FFE28A\",\"#FE9E43\",\"#FFC25E\",\"#FFEC9E\",\"#FD6830\",\"#FFE997\",\"#FEA747\",\"#FFED9F\",\"#FD7C36\",\"#FFE187\",\"#FFEC9E\",\"#9C0026\",\"#FD923E\",\"#FFE794\",\"#FFE58F\",\"#FC512B\",\"#FFE58F\",\"#FD7333\",\"#FD6931\",\"#BD0026\",\"#FFE48D\",\"#FEA646\",\"#BE0126\",\"#BD0026\",\"#FFEA99\",\"#FFEDA0\",\"#FEAE4A\",\"#FFED9F\",\"#E1191D\",\"#FFE58F\",\"#FEA948\",\"#FFEC9F\",\"#FEB44E\",\"#F13B24\",\"#940026\",\"#FD7E37\",\"#FFE289\",\"#E31A1C\",\"#E6241E\",\"#BF0126\",\"#E41D1D\",\"#FD8539\",\"#FFC15C\",\"#FEB14B\",\"#EE3522\",\"#E41C1C\",\"#F13B24\",\"#B10026\",\"#E8281F\",\"#FEB852\",\"#FD883A\",\"#FD8339\",\"#BF0126\",\"#FD7033\",\"#BD0026\",\"#BC0026\",\"#EE3422\",\"#FFDF84\",\"#F13B24\",\"#FFED9F\",\"#FD7534\",\"#DB151F\",\"#CC0B23\",\"#FFCD69\",\"#FFE895\",\"#E1191D\",\"#E51F1D\",\"#FEB550\",\"#FFEDA0\",\"#FD923E\",\"#E7251E\",\"#FD5E2E\",\"#FFE793\",\"#FD953F\",\"#FFC35E\",\"#FEA647\",\"#FD6931\",\"#DE171E\",\"#C10325\",\"#FEB44E\",\"#F54126\",\"#E0181D\",\"#FEB34D\",\"#FFED9F\",\"#BF0226\",\"#FD642F\",\"#BF0126\",\"#F74627\",\"#FFED9F\",\"#FD7B36\",\"#FFEDA0\",\"#FE9C42\",\"#FEA747\",\"#FD893B\",\"#FFE48D\",\"#FFEA99\",\"#C00225\",\"#FFEFA4\",\"#FEDD7E\",\"#D8141F\",\"#FFE48E\",\"#FFEC9F\",\"#FFEDA0\",\"#FFEFA4\",\"#FFE896\",\"#FD933E\",\"#F74527\",\"#FD7133\",\"#FFEEA2\",\"#FFEEA2\",\"#FFEA9A\",\"#FFE793\",\"#E6241E\",\"#FEDB7B\",\"#FFC35F\",\"#FD873A\",\"#F33E25\",\"#FFE590\",\"#FFEC9F\",\"#FEDB79\",\"#900026\",\"#FFE793\",\"#FD8F3D\",\"#BD0026\",\"#FEAE4A\",\"#FED774\",\"#FD8F3D\",\"#FD612E\",\"#FFE998\",\"#FFDF83\",\"#F64426\",\"#FFF0A7\",\"#FFE895\",\"#FFE48C\",\"#C60624\",\"#FFBD58\",\"#E31A1C\",\"#FC5A2D\",\"#FD7333\",\"#FEBA54\",\"#FFE895\",\"#FFDE81\",\"#FEB650\",\"#FB4C29\",\"#EE3522\",\"#FFEC9E\",\"#FFE896\",\"#FFBE59\",\"#C10325\",\"#FFEA9A\",\"#FFCA65\",\"#FFEB9C\",\"#DF181D\",\"#C30425\",\"#FED875\",\"#FFF1A9\",\"#E0181D\",\"#FFED9F\",\"#FD8A3B\",\"#FEA948\",\"#FFE48E\",\"#FFE997\",\"#DF181D\",\"#FE9D43\",\"#FD5D2D\",\"#B70026\",\"#FFED9F\",\"#FEDA78\",\"#FFE998\",\"#FEDC7D\",\"#E92B1F\",\"#FD5E2E\",\"#F03A23\",\"#FFEEA3\",\"#C00225\",\"#C00225\",\"#DB151F\",\"#FFE795\",\"#FFE48D\",\"#E0181D\",\"#FFF1AA\",\"#F03A23\",\"#FFE38B\",\"#FD7D37\",\"#FFE085\",\"#FFE997\",\"#CE0D22\",\"#D8141F\",\"#FFF1A9\",\"#F33F25\",\"#D71320\",\"#FD602E\",\"#FFE895\",\"#BD0026\",\"#FFEC9F\",\"#FFE895\",\"#FEAE4A\",\"#FD632F\",\"#FEDB7A\",\"#FFE38C\",\"#B80026\",\"#FC552B\",\"#9D0026\",\"#FEB651\",\"#FFEDA0\",\"#E41D1D\",\"#FFE58F\",\"#E6241E\",\"#DE171E\",\"#E7261E\",\"#FC4E2A\",\"#FFE38B\",\"#FFE895\",\"#EA2E20\",\"#C80824\",\"#FEB954\",\"#FFE794\",\"#FFEDA0\",\"#FFE187\",\"#FFCA66\",\"#CB0A23\",\"#FFEA99\",\"#B70026\",\"#DB161F\",\"#FFEC9D\",\"#FB4C29\",\"#FFEFA5\",\"#DE171E\",\"#FD913E\",\"#FFED9F\",\"#ED3322\",\"#FFCC68\",\"#E21A1C\",\"#FFEA99\",\"#FEA546\",\"#C00225\",\"#FD5F2E\",\"#FFEDA1\",\"#FD7634\",\"#FFE48D\",\"#E6221D\",\"#FC562C\",\"#FFE897\",\"#FFE691\",\"#FFCB67\",\"#EF3622\",\"#FED16E\",\"#FFE590\",\"#FD7E37\",\"#FEDC7C\",\"#FD7B36\",\"#FFEA99\",\"#E41D1D\",\"#FD632F\",\"#FFEB9C\",\"#FEB44E\",\"#BF0225\",\"#F74527\",\"#FFE794\",\"#F94928\",\"#FD7E37\",\"#FFE998\",\"#C50624\",\"#C00225\",\"#FA4A29\",\"#E8271E\",\"#F03923\",\"#FC4D2A\",\"#F54226\",\"#C10325\",\"#FFEC9E\",\"#E1191D\",\"#FFC25D\",\"#BE0026\",\"#FFE794\",\"#FFE691\",\"#FFEA9A\",\"#DB151F\",\"#EF3723\",\"#FFE38A\",\"#E41F1D\",\"#FFEC9E\",\"#FFE48D\",\"#FD6931\",\"#CE0D22\",\"#EA2C20\",\"#EB2F20\",\"#FFE997\",\"#FD6930\",\"#FFE38B\",\"#FEAC49\",\"#C10325\",\"#FFE58F\",\"#F54226\",\"#B80026\",\"#FFE38C\",\"#F03923\",\"#FFE997\",\"#E8281F\",\"#FFE999\",\"#FFEDA0\",\"#FED16E\",\"#FEDD7E\",\"#EB3020\",\"#C30425\",\"#E2191C\",\"#FC552C\",\"#FD953F\",\"#C70724\",\"#E31A1C\",\"#FC562C\",\"#FFEB9C\",\"#FFEEA1\",\"#FD602E\",\"#FC502A\",\"#E8281F\",\"#FE9F43\",\"#D71320\",\"#940026\",\"#FEAA48\",\"#FFEDA0\",\"#BB0026\",\"#FFE187\",\"#E5211D\",\"#BF0126\",\"#FC532B\",\"#FEAD4A\",\"#FFF2AC\",\"#FED06C\",\"#FC4E2A\",\"#FFEC9D\",\"#FED875\",\"#FD7C36\",\"#FFE793\",\"#FFDF83\",\"#FFE691\",\"#F84828\",\"#EF3622\",\"#FFE895\",\"#FD7334\",\"#FFC864\",\"#FED875\",\"#FFF0A7\",\"#930026\",\"#FEDB7B\",\"#FFEC9E\",\"#ED3321\",\"#FED06D\",\"#F64527\",\"#FFEC9F\",\"#FFEDA0\",\"#FED673\",\"#FED977\",\"#C30425\",\"#FD7634\",\"#FD943F\",\"#FFE794\",\"#F33E25\",\"#FFE084\",\"#FD7634\",\"#FD7835\",\"#FFE794\",\"#ED3321\",\"#FD6630\",\"#FD6E32\",\"#FC5A2D\",\"#DD171E\",\"#FED977\",\"#FE9941\",\"#FEA446\",\"#FD6630\",\"#FFE590\",\"#DE171E\",\"#FFEC9D\",\"#FFC965\",\"#D21021\",\"#FFE793\",\"#C30425\",\"#E92B1F\",\"#FD913E\",\"#FD903D\",\"#800026\",\"#FFE28A\",\"#FEB04B\",\"#D31021\",\"#DD171E\",\"#D9141F\",\"#FFEA9A\",\"#F94928\",\"#FFC965\",\"#FFE793\",\"#FD8238\",\"#FD632F\",\"#FFEC9E\",\"#FD5B2D\",\"#FC512B\",\"#C10325\",\"#FFEC9F\",\"#FD6630\",\"#FED673\",\"#C00225\",\"#FFE997\",\"#F94928\",\"#FD8339\",\"#FEAC49\",\"#FEDC7C\",\"#FB4D29\",\"#FD7233\",\"#F03A23\",\"#FFE288\",\"#FC512B\",\"#FFE58F\",\"#FFEC9D\",\"#FFE085\",\"#E2191C\",\"#FFFFCC\",\"#FFCC68\",\"#E7261E\",\"#FC4F2A\",\"#D71320\",\"#FFE38B\",\"#FFEC9E\",\"#FD6E32\",\"#FD7133\",\"#FFEB9C\",\"#FEDD7F\",\"#FD7634\",\"#FEAE4A\",\"#FFEEA4\",\"#FD6630\",\"#E7251E\",\"#FFEC9D\",\"#FD8539\",\"#E31A1C\",\"#FFC25D\",\"#E6231E\",\"#FFF0A8\",\"#FFEB9C\",\"#FFE590\",\"#FFEFA4\",\"#FFE999\",\"#FD8339\",\"#C20425\",\"#FC592C\",\"#FD6630\",\"#FFC762\",\"#FD8539\",\"#E6231E\",\"#FD7133\",\"#FFF3AF\",\"#930026\",\"#FA4B29\",\"#FA4B29\",\"#FD7032\",\"#FD6B31\",\"#FC532B\",\"#FED16D\",\"#FD7434\",\"#FEA245\",\"#FA4B29\",\"#FEDD7E\",\"#F64426\",\"#930026\",\"#FD5C2D\",\"#BE0126\",\"#FEAF4B\",\"#FD883A\",\"#FD6A31\",\"#FFEDA1\",\"#FFEDA0\",\"#FFDE81\",\"#C10325\",\"#FFEC9F\",\"#F64527\",\"#D51220\",\"#FFE48D\",\"#F13B24\",\"#FFE58F\",\"#E6231E\",\"#FFE895\",\"#FEB34D\",\"#FA4B29\",\"#BE0126\",\"#FD652F\",\"#E21A1C\",\"#FED26F\",\"#FFE998\",\"#FFBF5A\",\"#D31021\",\"#FFEA9A\",\"#D41121\",\"#FFEC9D\",\"#D9141F\",\"#FED976\",\"#FFEB9D\",\"#FD622F\",\"#F13A24\",\"#FFEEA4\",\"#FD8439\",\"#F64427\",\"#ED3422\",\"#FEDC7C\",\"#FEA948\",\"#CA0A23\",\"#FFE998\",\"#FFED9F\",\"#E6241E\",\"#FFBD58\",\"#FFEEA3\",\"#FD953F\",\"#FFE48E\",\"#FFE38C\",\"#FE9740\",\"#FFE187\",\"#FFEDA1\",\"#FEA848\",\"#FEDB7B\",\"#E2191D\",\"#FFEEA2\",\"#DB161E\",\"#BD0026\",\"#C70724\",\"#FEBA54\",\"#F03923\",\"#FFEDA0\",\"#FFE691\",\"#FFEDA0\",\"#FEAE4A\",\"#F94928\",\"#FEA345\",\"#FE9A41\",\"#DE171E\",\"#F44126\",\"#870026\",\"#BE0126\",\"#FD6930\",\"#F84728\",\"#FC562C\",\"#FFE187\",\"#FFF1AA\",\"#F23D24\",\"#E7241E\",\"#FD6C31\",\"#EF3823\",\"#BF0126\",\"#F84727\",\"#D51220\",\"#FFE998\",\"#FEBB55\",\"#F84728\",\"#FFE48E\",\"#DF181D\",\"#FD6D32\",\"#FFEDA0\",\"#FD933E\",\"#FFBF5A\",\"#FEBB55\",\"#9E0026\",\"#FFE999\",\"#FFEEA3\",\"#FFBF5A\",\"#F84828\",\"#B50026\",\"#E1191D\",\"#FED26E\",\"#FD7534\",\"#FEB54F\",\"#BF0126\",\"#FED06C\",\"#FD8038\",\"#C20325\",\"#DD171E\",\"#FE9A41\",\"#FFE896\",\"#E7261E\",\"#FEA546\",\"#FEDB79\",\"#E0181D\",\"#FFE998\",\"#FFEEA2\",\"#FD652F\",\"#CE0D22\",\"#BF0126\",\"#FFE187\",\"#FEAF4B\",\"#C10325\",\"#F94828\",\"#C20325\",\"#FFEFA6\",\"#BF0126\",\"#E2191C\",\"#E8271E\",\"#EC3021\",\"#FFEDA1\",\"#FC572C\",\"#FFE999\",\"#FED572\",\"#CC0B23\",\"#FD903D\",\"#FD863A\",\"#C00225\",\"#E8291F\",\"#FEDA79\",\"#E2191C\",\"#FFE997\",\"#DE171E\",\"#EE3622\",\"#C10325\",\"#C00225\",\"#E8291F\",\"#FED370\",\"#FFE897\",\"#FFEDA1\",\"#FFE895\",\"#FB4C29\",\"#D61220\",\"#DA151F\",\"#E41D1C\",\"#FD7D37\",\"#D21021\",\"#FFEA99\",\"#FFEC9E\",\"#FD863A\",\"#E6241E\",\"#FFEB9B\",\"#F54226\",\"#D9141F\",\"#D41121\",\"#FE9F43\",\"#FEDA78\",\"#FFED9F\",\"#EE3622\",\"#A90026\",\"#F54226\",\"#C20325\",\"#FFE28A\",\"#FED471\",\"#BF0126\",\"#F23D24\",\"#E5211D\",\"#EF3722\",\"#FFF1A9\",\"#BB0026\",\"#FFF5B3\",\"#FFEEA2\",\"#FFE691\",\"#FFEB9C\",\"#FD8A3B\",\"#FC562C\",\"#FD8D3C\",\"#FFE38B\",\"#FFF4B1\",\"#DF171D\",\"#D41121\",\"#ED3422\",\"#FFE38B\",\"#DC161E\",\"#F44125\",\"#FEA446\",\"#940026\",\"#FFF1AB\",\"#FFE998\",\"#FD7334\",\"#FFEEA3\",\"#FE9E43\",\"#E1191D\",\"#B90026\",\"#FC5A2D\",\"#FD7A36\",\"#FFE896\",\"#FFE794\",\"#FFC662\",\"#BD0026\",\"#FEBC57\",\"#D71320\",\"#F23C24\",\"#FD7A36\",\"#E1191D\",\"#CE0D22\",\"#FFC661\",\"#FFEB9C\",\"#FD8439\",\"#FFEC9E\",\"#FFEC9E\",\"#FFE897\",\"#FEB751\",\"#F84828\",\"#FFEB9D\",\"#FFE084\",\"#EF3823\",\"#EC3121\",\"#C40525\",\"#C20325\",\"#FD6830\",\"#FEB54F\",\"#CB0A23\",\"#FFE895\",\"#FFE998\",\"#FD5F2E\",\"#FFEDA0\",\"#D9141F\",\"#DA151F\",\"#FFE187\",\"#FE9C42\",\"#E41C1C\",\"#FEDB7B\",\"#FD6C31\",\"#FECF6C\",\"#FFE38C\",\"#FFE895\",\"#FD8439\",\"#FFCB67\",\"#FD8D3C\",\"#FD8138\",\"#FD6931\",\"#F13A23\",\"#FFCB67\",\"#FFED9F\",\"#FD652F\",\"#F74627\",\"#DD161E\",\"#FEDC7D\",\"#E41D1C\",\"#FFEEA2\",\"#FFC05B\",\"#CD0C22\",\"#FFE692\",\"#FFEFA5\",\"#FFC15D\",\"#FFEA9A\",\"#DB151F\",\"#F33E25\",\"#F03A23\",\"#FEB853\",\"#BB0026\",\"#C60624\",\"#FFEEA2\",\"#FEAD4A\",\"#F84727\",\"#F33E25\",\"#FFC560\",\"#FFEC9D\",\"#FFF0A7\",\"#FD7133\",\"#FD873A\",\"#FE9A41\",\"#FFCB66\",\"#BA0026\",\"#F03A23\",\"#FC562C\",\"#FFE895\",\"#FD8A3B\",\"#FD5F2E\",\"#FEB54F\",\"#BE0026\",\"#ED3422\",\"#FFEEA2\",\"#FFE48E\",\"#FFEDA0\",\"#FD943F\",\"#FD7033\",\"#FFEEA2\",\"#F94928\",\"#FFEB9B\",\"#FFF3AF\",\"#FD873A\",\"#E2191C\",\"#940026\",\"#CA0A23\",\"#FEDB79\",\"#FFEA99\",\"#FFEA99\",\"#E92B1F\",\"#FC4F2A\",\"#FEB24C\",\"#D71320\",\"#FFF0A7\",\"#BB0026\",\"#F33E25\",\"#FFEA9A\",\"#C10325\",\"#FFED9F\",\"#FFEA99\",\"#DE171E\",\"#FEAB49\",\"#FFE692\",\"#E31B1C\",\"#C00225\",\"#FE9D43\",\"#F54226\",\"#FFEDA0\",\"#FFE692\",\"#FFEEA2\",\"#BF0126\",\"#EE3422\",\"#FFE48D\",\"#B70026\",\"#FD7032\",\"#FFCE6B\",\"#FD7D36\",\"#FD8539\",\"#FFED9F\",\"#FD8038\",\"#FFE691\",\"#FD6C31\",\"#F74627\",\"#FD7F37\",\"#A40026\",\"#E41C1C\",\"#FFEC9E\",\"#F54226\",\"#FD913E\",\"#FEDD7E\",\"#DE171E\",\"#FFEFA4\",\"#FD6B31\",\"#FFEEA3\",\"#FFCB67\",\"#FC532B\",\"#FFEB9C\",\"#E41D1D\",\"#EF3723\",\"#DD161E\",\"#FEB04B\",\"#FC4E2A\",\"#FC4E2A\",\"#FD883A\",\"#DC161E\",\"#C80824\",\"#EC3121\",\"#FFE28A\",\"#FFED9F\",\"#FEDC7C\",\"#C20325\",\"#BE0026\",\"#FFE895\",\"#FD7835\",\"#FFF2AD\",\"#FFEB9B\",\"#FFE188\",\"#FEA345\",\"#FEA546\",\"#C00225\",\"#FFE793\",\"#E6241E\",\"#FEBB56\",\"#FEAA48\",\"#F84728\",\"#FFF3AE\",\"#DF181D\",\"#D21021\",\"#FFF1A9\",\"#860026\",\"#E31A1C\",\"#FD8038\",\"#FEAC49\",\"#F54226\",\"#FFE48D\",\"#FFE999\",\"#FEB44E\",\"#DC161E\",\"#FC532B\",\"#FC572C\",\"#BD0026\",\"#F33E25\",\"#F84828\",\"#FEB24C\",\"#DF181D\",\"#DB151F\",\"#FC512B\",\"#EA2D20\",\"#F03A23\",\"#FFE896\",\"#FD9640\",\"#FFEB9B\",\"#FED673\",\"#FFEB9D\",\"#FFE48E\",\"#FFEC9D\",\"#BD0026\",\"#FFEDA1\",\"#FEA647\",\"#FEDC7D\",\"#F64426\",\"#DE171E\",\"#FFE188\",\"#F74527\",\"#FEA446\",\"#F03923\",\"#E1191D\",\"#FFEC9E\",\"#DE171E\",\"#E6231E\",\"#F94928\",\"#FFE187\",\"#F64326\",\"#FFCC68\",\"#FD6A31\",\"#FEB853\",\"#FA4B29\",\"#FFEEA2\",\"#FFEDA1\",\"#9C0026\",\"#FFED9F\",\"#CE0D22\",\"#BD0026\",\"#EF3723\",\"#F03923\",\"#F44126\",\"#E7251E\",\"#FE9840\",\"#CA0A23\",\"#FFEB9C\",\"#FC562C\",\"#FD923E\",\"#DE171E\",\"#FFEEA2\",\"#C40525\",\"#C30425\",\"#FD6630\",\"#FFEB9B\",\"#FC4F2A\",\"#FE9F44\",\"#FFEEA2\",\"#FFED9F\",\"#FFE085\",\"#FFEFA5\",\"#BD0026\",\"#FEAE4A\",\"#FFE895\",\"#F84728\",\"#FFEA9B\",\"#E1191D\",\"#FFEB9D\",\"#FFE794\",\"#F44025\",\"#E1191D\",\"#BA0026\",\"#FFE692\",\"#FD6830\",\"#FFE998\",\"#F33F25\",\"#FFE38B\",\"#FFE998\",\"#FFED9F\",\"#FE9F43\",\"#FEA446\",\"#FFF2AD\",\"#FFE186\",\"#E5211D\",\"#FC502A\",\"#E7251E\",\"#BE0126\",\"#FFEEA2\",\"#FD863A\",\"#FEB24C\",\"#FD7E37\",\"#ED3221\",\"#FFEB9B\",\"#FFEC9F\",\"#BB0026\",\"#FD7D37\",\"#FD8439\",\"#FFE48C\",\"#BF0226\",\"#DD171E\",\"#FFE998\",\"#EA2E20\",\"#FFE186\",\"#FD7F37\",\"#FEDD7D\",\"#BC0026\",\"#960026\",\"#E31B1C\",\"#FED874\",\"#FA4A29\",\"#FFEDA0\",\"#FD8439\",\"#FFEA9B\",\"#BF0126\",\"#FD8038\",\"#BA0026\",\"#FFE085\",\"#F23D24\",\"#E6231E\",\"#EA2D20\",\"#DB151F\",\"#FFC35F\",\"#FFEB9D\",\"#FED572\",\"#FD622F\",\"#FFE085\",\"#E5201D\",\"#E51F1D\",\"#900026\",\"#FD8037\",\"#EA2D20\",\"#F44025\",\"#FD883A\",\"#FFCF6B\",\"#FD632F\",\"#DD161E\",\"#FEAB49\",\"#DF181D\",\"#FFE999\",\"#E31B1C\",\"#DC161E\",\"#C10325\",\"#FFCF6B\",\"#BC0026\",\"#FFE590\",\"#FD7E37\",\"#F74627\",\"#FFEEA3\",\"#FFEEA2\",\"#FE9A41\",\"#FFDE81\",\"#FFF0A7\",\"#FFEC9F\",\"#FEB14B\",\"#FD6F32\",\"#FC552C\",\"#FFEC9F\",\"#FFE48E\",\"#FEA847\",\"#BE0126\",\"#E0181D\",\"#ED3422\",\"#FFE590\",\"#D71320\",\"#D8141F\",\"#FFEEA1\",\"#FD6830\",\"#E2191C\",\"#FD6B31\",\"#B60026\",\"#BE0126\",\"#EC3021\",\"#FD7A36\",\"#F44025\",\"#960026\",\"#FFE895\",\"#FEAB49\",\"#FFF7B9\",\"#FFE794\",\"#F54226\",\"#FFEA9B\",\"#E7251E\",\"#C30425\",\"#FFE896\",\"#FD7735\",\"#F13A23\",\"#FD8B3B\",\"#FD8E3C\",\"#FFEB9D\",\"#FED471\",\"#FFEEA2\",\"#FFDE80\",\"#FFE187\",\"#FFE999\",\"#FFEEA4\",\"#FFE794\",\"#FD6B31\",\"#FFE793\",\"#FFE895\",\"#FFE794\",\"#FE9C42\",\"#DE171E\",\"#FFEC9E\",\"#FD8238\",\"#FFE38C\",\"#E7261E\",\"#F03923\",\"#FEAC49\",\"#CD0C22\",\"#FEAB49\",\"#FEB752\",\"#E1191D\",\"#FFEFA5\",\"#FFE692\",\"#FC582C\",\"#FD7334\",\"#C10325\",\"#F84727\",\"#B10026\",\"#FFE998\",\"#930026\",\"#C10225\",\"#C80824\",\"#D20F21\",\"#FFE187\",\"#DB151F\",\"#FE9740\",\"#FFEA9A\",\"#FFEC9D\",\"#FFE085\",\"#FFDF82\",\"#940026\",\"#E51F1D\",\"#FC562C\",\"#FD5C2D\",\"#BD0026\",\"#FD8539\",\"#D61320\",\"#FEB853\",\"#EA2D20\",\"#FD923E\",\"#ED3221\",\"#FFEC9D\",\"#DB161E\",\"#FEDB7B\",\"#FFE793\",\"#E6231E\",\"#FD913E\",\"#FFEEA3\",\"#FFEDA0\",\"#DB151F\",\"#FFF2AD\",\"#FFE793\",\"#A80026\",\"#FEDD7E\",\"#EB2F20\",\"#FFE186\",\"#FFEC9D\",\"#FFEDA1\",\"#B80026\",\"#F33F25\",\"#FD8038\",\"#FFBD58\",\"#C00225\",\"#FEDB7A\",\"#E9291F\",\"#FFE289\",\"#FFE895\"],\"fillOpacity\":1},null,null,null,null,null,{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]},{\"method\":\"addLegend\",\"args\":[{\"colors\":[\"#FFFFCC , #FFFFCB 0.274495763217589%, #FFEDA1 12.2090941639814%, #FEDA79 24.1436925647452%, #FEB651 36.078290965509%, #FD933E 48.0128893662728%, #FD5D2D 59.9474877670366%, #E92B1F 71.8820861678004%, #C80824 83.8166845685642%, #940026 95.751282969328%, #800026 \"],\"labels\":[\"1,950\",\"2,000\",\"2,050\",\"2,100\",\"2,150\",\"2,200\",\"2,250\",\"2,300\",\"2,350\"],\"na_color\":null,\"na_label\":\"NA\",\"opacity\":0.5,\"position\":\"bottomright\",\"type\":\"numeric\",\"title\":\"DIC\",\"extra\":{\"p_1\":0.00274495763217589,\"p_n\":0.95751282969328},\"layerId\":null,\"className\":\"info legend\",\"group\":null}]},{\"method\":\"addLayersControl\",\"args\":[[\"Satellite\",\"Street Map\"],\"Data\",{\"collapsed\":false,\"autoZIndex\":true,\"position\":\"topright\"}]}],\"limits\":{\"lat\":[30.4175,34.66333],\"lng\":[-124.00067,-117.3086]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n\n```{.r .cell-code}\nrm(color_palette)\n```\n:::\n\n\nThis was partially an exercise to see if DIC was correlated with distance from the coastline at all, which it doesn't appear to be.\n:::\n\n# Feature Engineering\n\nNow we're going to do some feature engineering. Feature engineering transforms existing data into new data, and helps improve our model performance by capturing relationships that might not be explicit in the data as it is. There are different types of feature engineering, but we're going to focus on using interaction terms. Interaction terms are used to capture the combined effect of two or more variables on our target variable, `DIC`. This is particularly important in our context because ocean chemistry is complicated, and we would like to use our domain knowledge to capture some of the relationships between our predictors.\n\nFor example, consider the relationship between depth `R_Depth` and salinity `R_Sal`. The interaction between depth and salinity can be explained by the fact that as water depth increases, pressure also increases, which affects the solubility of gases in seawater. Salinity also affects the solubility of gases in seawater, so the combined effect of depth and salinity may impact dissolved inorganic carbon levels.\n\nUsing this same approach, we are going to include interaction terms for temperature/salinity, and depth/temperature.\n\n::: panel-tabset\n### Python\n\nIn Python, we name the new interaction column and set it equal to the product of the terms we want to interact. We repeat this process for each interaction term.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Adding interaction terms to our training set\ntrain_py['T_degC_Salnty'] = train_py['Temperature_degC'] * train_py['Salinity1']\ntrain_py['Depth_Sal'] = train_py['R_Depth'] * train_py['R_Sal']\ntrain_py['Depth_Temp'] = train_py['R_Depth'] * train_py['Temperature_degC']\n\n# Same thing for the test set\ntest_py['T_degC_Salnty'] = test_py['Temperature_degC'] * test_py['Salinity1']\ntest_py['Depth_Sal'] = test_py['R_Depth'] * test_py['R_Sal']\ntest_py['Depth_Temp'] = test_py['R_Depth'] * test_py['Temperature_degC']\n```\n:::\n\n\nWe then make our training and testing objects. We split off `DIC` and assign it to the `y_test` and `y_train` variables below. This allows us to explicitly tell our models which columns we're using as features, and the outcome we want to predict.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Splitting off DIC in the training data\nX_train = train_py.drop(columns=['DIC'])\ny_train = train_py['DIC']\n\n# Same thing for the test data\nX_test = test_py.drop(columns=['DIC'])\ny_test = test_py['DIC']\n```\n:::\n\n\n### R\n\nWe can use the same approach to make our interaction terms in R with the `$` operator to initialize new columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Adding interaction terms to our training sets\ntraining$T_degC_Salnty <- training$Temperature_degC * training$Salinity1\ntraining$Depth_Sal <- training$R_Depth * training$R_Sal\ntraining$Depth_Temp <- training$R_Depth * training$Temperature_degC\n\n# Adding interaction terms to our test sets\ntesting$T_degC_Salnty <- testing$Temperature_degC * testing$Salinity1\ntesting$Depth_Sal <- testing$R_Depth * testing$R_Sal\ntesting$Depth_Temp <- testing$R_Depth * testing$Temperature_degC\n```\n:::\n\n\nIn R, the tidymodels package provides us with useful functions for splitting training and testing data. We stratify on DIC to ensure that our data is not disproportionately split on the outcome variable, which would bias our model. We also specify our cross-validation parameters using 5 folds, and create a recipe object that we will use throughout our analysis. This recipe object uses our specifications to normalize the numeric variables, and we will use this in each R model. We will also normalize in Python, using pipelines that we create separately for each model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Creating 5-fold CV\nfolds <- vfold_cv(data = training, v = 5, strata = DIC)\n\n# Creating our recipe object\nrec <- recipe(DIC ~ ., data = training) |> \n  step_normalize(all_numeric(), -DIC) |> \n  prep() \n```\n:::\n\n:::\n\n# Linear Regression\n\nLinear regression is the simplest model we can use to make predictions. It is an extremely powerful yet elegant technique used to model the relationship between one or more independent variables (predictors) and dependent variables (features). The basic form of the model is:\n\n$$\\operatorname{Y}=\\beta_0+\\beta_1  x +\\beta_n x_n + \\varepsilon $$ Where $\\beta_0$ is our intercept, $\\beta_1$, $\\beta_n$ are the coefficients of our independent variables, and $\\varepsilon$ is the difference between the observed values and the values predicted by our model. We're going to be evaluating our model performance using the Root Mean Squared Error (RMSE) metric which represents the square root of the average squared differences between the predicted values and the actual observed values. This helps us quantify the difference between the predicted values generated by the model and the actual values of the target variable.\n\nWe're also going to try Lasso and Ridge regression here. Both of these follow the same concepts as regular linear regression, but they implement penalties based on slightly different metrics of the cost function. Ridge regression adds an L2 penalty term, which is the squared magnitude of the $\\beta$ coefficients. This penalty term is controlled by alpha, and prevents our model from overfitting the training data by shrinking the coefficients towards zero, thus reducing the variance of the model. Lasso on the other hand uses an L1 penalty term on the cost function, which is based on the absolute magnitude of the coefficients. This penalty term is controlled by lambda, and forces some of the coefficients to be exactly zero, eliminating irrelevant features from the model. Both of these may improve our models' performance.\n\n::: panel-tabset\n### Python\n\nIn Python, we first instantiate a linear regression model, fit it on the training data, and then predict on the holdout data.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# instantiate a Linear Regression model\nlr_model = LinearRegression()\n\n# fit the model to the training set\nlr_model.fit(X_train, y_train)\n\n# Predict on the test set\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\ny_test_pred_lr = lr_model.predict(X_test)\n\n# Calculate RMSE on our test set\nrmse_test_lr = mean_squared_error(y_test, y_test_pred_lr, squared=False)\n\nprint(f\"RMSE on the test set: {rmse_test_lr:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE on the test set: 4.93\n```\n:::\n:::\n\n\nAn RMSE of 4.93 is not bad at all! Lets take a look at what this actually looks like plotted through our data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# clear our plot\nplt.clf()\n# Create a scatter plot of the true DIC values vs predicted DIC values\nplt.scatter(y_test, y_test_pred_lr, alpha=0.5)\n\n# Add a diagonal line representing perfect predictions\ndiagonal_line = np.linspace(min(y_test.min(), y_test_pred_lr.min()),\n                            max(y_test.max(), y_test_pred_lr.max()))\nplt.plot(diagonal_line, diagonal_line, color='red', linestyle='--', lw=2)\n\n# Add labels, title and RMSE text\nplt.xlabel('True DIC values')\nplt.ylabel('Predicted DIC values')\nplt.title('True vs Predicted DIC values')\nplt.text(0.05, 0.95, f'RMSE: {rmse_test_lr:.2f}', transform=plt.gca().transAxes)\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-12-1.png){width=960}\n:::\n\n```{.python .cell-code}\ndel(lr_model, y_test_pred_lr)\n```\n:::\n\n\nThe red line here is what we would have observed if we correctly predicted each observation. The difference between the red line and the blue dots represent the difference between our model's prediction, and the actual value.\n\nNow we'll check out Ridge and Lasso regression. We follow the same approach as with linear regression but with one slight change. We specify the alpha parameter, which controls the strength of the penalty. This would usually be a tuning hyperparameter, which I'll explain in a second, but we're just going to use an alpha value of one.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nplt.clf()\n\n# Ridge Regression\nridge = Ridge(alpha=1)\nridge.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\nridge_preds = ridge.predict(X_test)\nridge_rmse = mean_squared_error(y_test, ridge_preds, squared=False)\nprint(\"Ridge RMSE:\", ridge_rmse)\n\n# Lasso Regression\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRidge RMSE: 4.928343737671815\n```\n:::\n\n```{.python .cell-code}\nlasso = Lasso(alpha=1)\nlasso.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=1)</pre></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\nlasso_preds = lasso.predict(X_test)\nlasso_rmse = mean_squared_error(y_test, lasso_preds, squared=False)\nprint(\"Lasso RMSE:\", lasso_rmse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLasso RMSE: 6.5330738340489605\n```\n:::\n\n```{.python .cell-code}\ndel(ridge, ridge_preds, lasso, lasso_preds)\n```\n:::\n\n\nWhile our ridge model achieved a comparable RMSE to our linear regression, our lasso model performed worse. This could be because the lasso model is shrinking important coefficients to zero. \n\n### R\n\nIn R, we use our recipe that we defined earlier, then create a linear regression model and a workflow. Our recipe object specifies the preprocessing steps required to transform the data, while the workflow includes both the preprocessing and the modeling steps. We add our recipe and model to our workflow, fit on the training data, and predict on the test data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First we create the model\nlm_model <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  set_mode(\"regression\")\n\n\n# we then make a workflow, analogous to a pipe in python\nlm_workflow <- workflow() |> \n  add_recipe(rec) |> \n  add_model(lm_model)\n\n# fit to training\nlm_fit <- fit(lm_workflow, data = training)\n\n# predict on the test data\ntesting_preds_lr <- predict(lm_fit, testing)\n\n# Calculate and store the RMSE\nrmse_test_lr <- rmse(testing_preds_lr, truth = testing$DIC, estimate = .pred)\nrmse_lr <- rmse_test_lr$.estimate\n\nprint(paste0(\"RMSE on the holdout set: \", round(rmse_lr, 3)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"RMSE on the holdout set: 4.933\"\n```\n:::\n\n```{.r .cell-code}\n# Create a scatter plot of the true DIC values vs predicted DIC values\nggplot(testing, aes(x = DIC, y = testing_preds_lr$.pred)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(\n    x = \"True DIC values\",\n    y = \"Predicted DIC values\",\n    title = \"True vs Predicted DIC values\"\n  ) +\n  annotate(\"text\", x = min(testing$DIC), y = max(testing$DIC), label = paste(\"RMSE:\", round(rmse_lr, 2)), hjust = 0, vjust = 1)\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-14-3.png){width=672}\n:::\n\n```{.r .cell-code}\nrm(lm_model, lm_workflow, lm_fit, testing_preds_lr, rmse_test_lr)\n```\n:::\n\n\nWe achieved a similar RMSE to our linear regression in python, which is reassuring. Now, lets try ridge and lasso penalties in R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ridge Regression, mixture=0 specifies that this is a ridge model\nridge_model <- linear_reg(penalty = 1, mixture = 0) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"regression\")\n\n# Ridge workflow, add our recipe and model\nridge_workflow <- workflow() |> \n  add_recipe(rec) |> \n  add_model(ridge_model)\n\n# Fit on the training, predict on the test data, store the RMSEs\nridge_fit <- fit(ridge_workflow, data = training)\nridge_testing_preds <- predict(ridge_fit, testing)\nridge_rmse <- as.numeric(rmse(ridge_testing_preds, truth = testing$DIC, estimate = .pred)[,3])\nprint(paste(\"Ridge RMSE:\", round(ridge_rmse, 2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Ridge RMSE: 7.89\"\n```\n:::\n\n```{.r .cell-code}\n# Same approach for lasso regression, this time using mixture=1 for lasso\nlasso_model <- linear_reg(penalty = 1, mixture = 1) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"regression\")\n\n# workflow, same as before\nlasso_workflow <- workflow() |> \n  add_recipe(rec) |> \n  add_model(lasso_model)\n# fit on the training and predict on the test\nlasso_fit <- fit(lasso_workflow, data = training)\nlasso_testing_preds <- predict(lasso_fit, testing)\nlasso_rmse <- as.numeric(rmse(lasso_testing_preds, truth = testing$DIC, estimate = .pred)[,3])\nprint(paste(\"Lasso RMSE:\", round(lasso_rmse, 2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Lasso RMSE: 5.39\"\n```\n:::\n\n```{.r .cell-code}\nrm(ridge_model, ridge_workflow, ridge_fit, lasso_model, lasso_workflow, lasso_fit, ridge_testing_preds, lasso_testing_preds)\n```\n:::\n\n\nBoth of these models in R performed worse than our regular linear regression model.\n:::\n\nOur ridge and lasso models both performed slightly worse than our regular linear regression. This could be because we chose poor values of `penalty`, which we could address by tuning this hyperparameter. This could also simply be because our penalties might be penalizing coefficients that are actually important for predicting the outcome variable. This can happen when there is high correlation between the predictors.\n\n# KNN\n\nThe next model we want to try is K-Nearest Neighbors. Usually, this algorithm is used for classification, and would not be my first choice for a regression task. In the context of classification, KNN is used to predict the category of an unknown data point based on the categories of its neighboring data points. Given a scatterplot of data points belonging to different classes (for example, measurements of tree height and leaf width of two distinct species), the algorithm considers a specified number of the closest points (neighbors) to the unknown data point. The unknown point is then assigned a category based on the majority class of these neighbors. KNN can also be applied to regression tasks, where the goal is to predict a continuous value instead of a discrete category. Here, the algorithm again looks at the specified number of nearest neighbors to the unknown data point. However, instead of determining the majority class, it computes the average of the target values of these neighbors. The unknown point is then assigned this average value as its prediction.\n\nWe are also tuning our first hyperparameter here: the number of neighbors we want to use. We're going to use grid searching to find the optimal k, essentially making a grid of a range of values that we expect our optimal value for k to fall within. We search over this grid, test each of the values, and find the value that performs best on the training set. It is important to find the right k-value, as too small of a k will result in overfitting while too large of a k will result in underfitting. We will be using this approach with all models going forward.\n\n::: panel-tabset\n### Python\n\nWe follow a slightly different workflow to our linear regression model in python now that we have a tuning parameter. We instantiate the model, specify the number of neighbors we want to test (typically the square root of the total number of observations in the dataset is a good rule of thumb)\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Instantiate our knn regressor\nknn_regressor = KNeighborsRegressor()\n\n# Define the parameter grid for hyperparameter tuning - we want to test all numbers of n_neighbors from 1 to 34\nparam_grid = {'knn__n_neighbors': list(range(1, 35))}\n\n# Create a pipeline with StandardScaler and KNeighborsRegressor\nknn_pipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('knn', knn_regressor)\n])\n\n# Perform GridSearchCV for hyperparameter tuning\ngrid_search = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='neg_root_mean_squared_error')\n\n# fit on the training\ngrid_search.fit(X_train, y_train)  \n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;knn&#x27;, KNeighborsRegressor())]),\n             param_grid={&#x27;knn__n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n                                              12, 13, 14, 15, 16, 17, 18, 19,\n                                              20, 21, 22, 23, 24, 25, 26, 27,\n                                              28, 29, 30, ...]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;knn&#x27;, KNeighborsRegressor())]),\n             param_grid={&#x27;knn__n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n                                              12, 13, 14, 15, 16, 17, 18, 19,\n                                              20, 21, 22, 23, 24, 25, 26, 27,\n                                              28, 29, 30, ...]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;knn&#x27;, KNeighborsRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\nWe can take a look at how our RMSE changes with different values of k:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# first, clear the figure\nplt.clf()\n# Get the mean cross-validated scores for each n_neighbors\ncv_scores = grid_search.cv_results_['mean_test_score']  \n\ncv_scores = -cv_scores\n\n# Plot RMSE vs. n_neighbors\nplt.figure(figsize=(8, 6))\nplt.plot(list(range(1, 35)), cv_scores, marker='o')\nplt.xlabel('Number of Neighbors (n_neighbors)')\nplt.ylabel('Mean Cross-Validated RMSE')\nplt.title('RMSE vs. n_neighbors')\nplt.grid()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-17-1.png){width=768}\n:::\n:::\n\n\nIt looks like our best value for k is 3.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# fit on the training\ngrid_search.fit(X_train, y_train)\n\n# Retrieve the best KNN model\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;knn&#x27;, KNeighborsRegressor())]),\n             param_grid={&#x27;knn__n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n                                              12, 13, 14, 15, 16, 17, 18, 19,\n                                              20, 21, 22, 23, 24, 25, 26, 27,\n                                              28, 29, 30, ...]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;knn&#x27;, KNeighborsRegressor())]),\n             param_grid={&#x27;knn__n_neighbors&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n                                              12, 13, 14, 15, 16, 17, 18, 19,\n                                              20, 21, 22, 23, 24, 25, 26, 27,\n                                              28, 29, 30, ...]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;knn&#x27;, KNeighborsRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\nbest_knn = grid_search.best_estimator_\n\n# predict on the test set\ny_pred = grid_search.predict(X_test)\n\n# get our RMSE\nrmse_knn = mean_squared_error(y_test, y_pred, squared=False)\n\nprint(\"Root Mean Squared Error: \", rmse_knn)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRoot Mean Squared Error:  11.332377692549752\n```\n:::\n\n```{.python .cell-code}\ndel(knn_regressor, param_grid, grid_search, best_knn, y_pred)\n```\n:::\n\n\nRMSE is noticeably worse than our regularized and ordinary linear regression models.\n\n### R\n\nWe follow the same approach in R, this time specifying in the model specification that we want to tune the number of neighbors. We make a grid of possible values for our number of neighbors parameter, find the optimal value, then use this value to fit on the training and predict on the test set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make our model\nknn_spec <- nearest_neighbor(neighbors = tune()) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"regression\")\n\n# Create a grid\nk_grid <- grid_regular(\n  neighbors(range = c(1, 34)),\n  levels = 30\n)\n\n# make our workflow\nknn_workflow <- workflow() |> \n  add_model(knn_spec) |> \n  add_recipe(rec)\n\n# tune it!\nknn_tuned <- tune_grid(\n  knn_workflow,\n  resamples = folds,\n  grid = k_grid,\n  metrics = metric_set(rmse)\n)\n\n# Get our optimal value for k\nbest_k <- knn_tuned |> \n  collect_metrics() |> \n  filter(.metric == \"rmse\") |> \n  arrange(mean) |> \n  slice(1) |> \n  pull(neighbors)\n```\n:::\n\n\nWe can also check how our RMSE changes with different values of our `n_neighbors` hyperparameter in R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the RMSE for each n_neighbors from the tuning results\nknn_tuning_metrics <- knn_tuned |> \n  collect_metrics() |> \n  filter(.metric == \"rmse\")\n\n# Plot RMSE vs. n_neighbors\nggplot(knn_tuning_metrics, aes(x = neighbors, y = mean)) +\n  geom_point() +\n  geom_line() +\n  theme_minimal() +\n  labs(\n    title = \"RMSE vs. n_neighbors\",\n    x = \"Number of Neighbors (n_neighbors)\",\n    y = \"Mean Cross-Validated RMSE\"\n  ) +\n  theme(plot.title = element_text(hjust = 0.5))\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nOur best value for K looks to be 5 in R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Update our model using our best k\nknn_spec_best <- nearest_neighbor(neighbors = best_k) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"regression\")\n\n# Fit the final model on the whole training set\nknn_final <- knn_workflow |> \n  update_model(knn_spec_best) |> \n  fit(data = training)\n\n# Make predictions on the test set\nknn_testing_preds <- predict(knn_final, testing) |> \n  bind_cols(testing) |> \n  mutate(truth = as.double(DIC), estimate = as.double(.pred)) |> \n  metrics(truth = truth, estimate = estimate)\n\n# RMSE\nrmse_knn <- knn_testing_preds |> \n  filter(.metric == \"rmse\") |> \n  pull(.estimate)\n\nprint(paste0(\"Our KNN RMSE is: \", rmse_knn))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Our KNN RMSE is: 10.8203934359629\"\n```\n:::\n\n```{.r .cell-code}\nrm(knn_spec, knn_spec_best, best_k, knn_final, knn_testing_preds, knn_tuned, k_grid, knn_workflow)\n```\n:::\n\n\nAgain, our KNN model performs poorly here.\n:::\n\nOur RMSE in both of these KNN models were noticeably worse than any of the ordinary linear regression models. No surprises here, this is not a scenario in which we would typically use KNN. Now, we're going to move on to the tree-based models.\n\n# Decision Tree\n\nThe next algorithm we're going to try is the decision tree. Decision trees are a popular algorithm used for both classification and regression tasks. They work by recursively splitting the input data into subsets based on the values of the input features, giving you a tree like structure. Each node in the tree represents a decision rule or condition based on the feature values, while the leaf/terminal nodes represent the final predicted class or value. The process of building a decision tree involves selecting the best feature to split the data at each node, usually based on a criterion such as information gain (for classification) or mean squared error (for regression). The tree continues to grow by making further splits until a stopping criterion is met, such as a minimum number of samples per leaf, a maximum depth of the tree, or a threshold for the improvement in the splitting criterion. A much more comprehensive explanation is [here](https://bradleyboehmke.github.io/HOML/DT.html).\n\nDecision trees are great, but can be prone to overfitting. Fortunately, we have hyperparameters to combat this. We're tuning 3 hyperparameters in this model. The cost complexity penalty, the maximum tree depth, and the minimum leaf samples. The cost complexity is used to \"prune\" the trees - reducing overfitting by removing branches of the decision tree that do not improve the accuracy of the model. This is similar to our alpha parameter in Lasso/Ridge regression, but penalizes the tree for having too many nodes. The maximum tree depth hyperparameter sets the maximum depth of the decision tree, or the number of levels the tree can have. A deeper tree is more likely to be overfitting the training data. Finally, the minimum number of samples required to be in a leaf node hyperparameter also helps us prevent overfitting and controlling tree depth by requiring a minimum number of samples in each leaf node.\n\nIt should be noted, unlike our KNN model, decision trees and their ensembles like random forests and bagged trees are generally not very sensitive to the scale of the input features because they make decisions based on the relative ordering of feature values, rather than the magnitudes of those values. But since we're using the same recipe object `rec` for each model in R, all of our features are automatically scaled. We will use the same approach in python, by explicitly creating a Pipeline object with a scaler inside of it for each model.\n\n::: panel-tabset\n### Python\n\nWe're introducting our first pipeline object here. This object is analogous to a workflow in R. We pass it the preprocessing steps we want to use on our data, and our model. We fit this pipeline object to the training data, and predict on the test data.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# Create a pipeline with a scaler and the decision tree regressor\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('dt_regressor', DecisionTreeRegressor(random_state=4))\n])\n\n# Define the parameter grid for hyperparameter tuning\nparam_grid = {\n    'dt_regressor__ccp_alpha': np.logspace(-4, 0, 20), # np.logspace(-4, 0, 5)\n    'dt_regressor__max_depth': list(range(1, 13)), # list(range(1, 21))\n    'dt_regressor__min_samples_leaf': list(range(1, 13)) # list(range(1, 21))\n}\n\n# Perform GridSearchCV for hyperparameter tuning using the pipeline\ngrid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;dt_regressor&#x27;,\n                                        DecisionTreeRegressor(random_state=4))]),\n             n_jobs=-1,\n             param_grid={&#x27;dt_regressor__ccp_alpha&#x27;: array([1.00000000e-04, 1.62377674e-04, 2.63665090e-04, 4.28133240e-04,\n       6.95192796e-04, 1.12883789e-03, 1.83298071e-03, 2.97635144e-03,\n       4.83293024e-03, 7.84759970e-03, 1.27427499e-02, 2.06913808e-02,\n       3.35981829e-02, 5.45559478e-02, 8.85866790e-02, 1.43844989e-01,\n       2.33572147e-01, 3.79269019e-01, 6.15848211e-01, 1.00000000e+00]),\n                         &#x27;dt_regressor__max_depth&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                     10, 11, 12],\n                         &#x27;dt_regressor__min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6, 7,\n                                                            8, 9, 10, 11, 12]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;dt_regressor&#x27;,\n                                        DecisionTreeRegressor(random_state=4))]),\n             n_jobs=-1,\n             param_grid={&#x27;dt_regressor__ccp_alpha&#x27;: array([1.00000000e-04, 1.62377674e-04, 2.63665090e-04, 4.28133240e-04,\n       6.95192796e-04, 1.12883789e-03, 1.83298071e-03, 2.97635144e-03,\n       4.83293024e-03, 7.84759970e-03, 1.27427499e-02, 2.06913808e-02,\n       3.35981829e-02, 5.45559478e-02, 8.85866790e-02, 1.43844989e-01,\n       2.33572147e-01, 3.79269019e-01, 6.15848211e-01, 1.00000000e+00]),\n                         &#x27;dt_regressor__max_depth&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                     10, 11, 12],\n                         &#x27;dt_regressor__min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6, 7,\n                                                            8, 9, 10, 11, 12]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;dt_regressor&#x27;, DecisionTreeRegressor(random_state=4))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=4)</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# Make predictions and evaluate the model\ny_pred = grid_search.predict(X_test)\ndt_rmse = mean_squared_error(y_test, y_pred, squared=False)\nprint(\"Best Decision Tree parameters: \", grid_search.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest Decision Tree parameters:  {'dt_regressor__ccp_alpha': 0.03359818286283781, 'dt_regressor__max_depth': 11, 'dt_regressor__min_samples_leaf': 5}\n```\n:::\n\n```{.python .cell-code}\nprint(\"RMSE: \", dt_rmse)\n\n\n# Clear our environment\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE:  6.711271577254955\n```\n:::\n\n```{.python .cell-code}\ndel(pipe, param_grid, grid_search, y_pred)\n```\n:::\n\n\nOur RMSE for this decision tree algorithm is 6.7. Much better than the KNN regressor!\n\n### R\n\nWe follow the same approach as we did for KNN in R. We specify the parameters we want to tune in the model specification, make a grid of values to try, and select the best values for our final model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# decision tree model specification, specifying our hyperparameters to tune. \ndt_spec <- decision_tree(\n    mode = \"regression\",\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune()\n  ) |> \n  set_engine(\"rpart\") |> \n  set_mode(\"regression\")\n\n# Define the parameter grid for hyperparameter tuning\nparam_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)\n\n# workflow\ndt_workflow <- workflow() |> \n  add_model(dt_spec) |> \n  add_recipe(rec)\n\n\n# tune our parameters\nregisterDoParallel(cores = n_cores)\ndt_tuned <- tune_grid(\n  dt_workflow,\n  resamples = folds,\n  grid = param_grid,\n  metrics = metric_set(rmse),\n  control = control_grid(save_pred = TRUE, parallel_over = \"everything\")\n)\n\n# extract the best values\nbest_params <- dt_tuned |> \n  show_best(\"rmse\") |> \n  slice(1) |> \n  select(cost_complexity, tree_depth, min_n) \n\nbest_cc <- best_params$cost_complexity\nbest_depth <- best_params$tree_depth\nbest_min_n <- best_params$min_n\n\nprint(paste0(\"Best cost complexity parameter: \", best_cc))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Best cost complexity parameter: 1e-10\"\n```\n:::\n\n```{.r .cell-code}\nprint(paste0(\"Best maximum tree depth: \", best_depth))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Best maximum tree depth: 15\"\n```\n:::\n\n```{.r .cell-code}\nprint(paste0(\"Best minimum number of samples in a leaf: \", best_min_n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Best minimum number of samples in a leaf: 11\"\n```\n:::\n:::\n\n\nWe can also use this autoplot function to visualize our best hyperparameter combinations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(dt_tuned)\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nWe now use these best values in our final model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the final decision tree model with the best hyperparameters\ndt_final <- decision_tree(\n  cost_complexity = best_cc,\n  tree_depth = best_depth,\n  min_n = best_min_n\n) |> \n  set_engine(\"rpart\") |> \n  set_mode(\"regression\")\n\n\n# fit to the training\ndt_final_fit <- dt_workflow |> \n  update_model(dt_final) |> \n  fit(data = training)\n\n# predict on the test set\ndt_testing_preds <- predict(dt_final_fit, testing) |> \n  bind_cols(testing) |> \n  mutate(truth = as.double(DIC), estimate = as.double(.pred)) |> \n  metrics(truth = truth, estimate = estimate)\n\ndt_rmse <- dt_testing_preds |>  filter(.metric == \"rmse\") |>  pull(.estimate)\n\nprint(best_params)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 Ã 3\n  cost_complexity tree_depth min_n\n            <dbl>      <int> <int>\n1    0.0000000001         15    11\n```\n:::\n\n```{.r .cell-code}\nprint(paste0(\"RMSE:\", dt_rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"RMSE:6.6869703721755\"\n```\n:::\n\n```{.r .cell-code}\nrm(dt_testing_preds, dt_tuned, dt_final_fit, dt_final, dt_spec, best_params, dt_workflow)\n```\n:::\n\nAgain, our decision tree in R performs much better than the KNN algorithm we used. \n:::\n\nThe decision tree model will be the foundation for the next 3 models we are going to try. Bagged Trees, Random Forests, and Gradient Boosting all use decision trees as their base learner, but with slight adjustments to how the final model is constructed.\n\n# Bagged Trees\n\nOur normal decision tree algorithm worked well, but there are some significant improvements we can make to this algorithm. Bagging, or bootstrap aggregation is a technique that creates multiple models and then combines their predictions into a final output. Bootstrapping involves drawing samples from a dataset with replacement, to create new samples that are of the same size as the original dataset. By generating multiple samples of the data and predict the statistic of interest for each sample, we can aggregate these predictions into a final output that typically generalizes to unseen data much better than a model trained on a single dataset.\n\nIn the context of decision trees, this is an ensemble method that employs the bagging technique by training multiple decision trees on different subsets of the training data. In our case, the new predictions are made by averaging the predictions together from the individual base learners. This technique works particularly well on decision trees, since single decision trees are high variance learners. We're creating multiple decision trees on different subsets of the training data. Our model's stability and robustness are increased since the predictions are less sensitive to small changes in the training data. In other words, the variance of the model is reduced, which greatly helps us with avoiding overfitting. Bagged Trees also provide information about the importance of each feature in the model, because each tree is trained on a random subset of the features. This means that each tree will give different weights to different features, which can then be used to identify the most important ones.\n\nWe have an additional hyperparameter to train here: the number of trees we want to generate the final bagged model from. Aside from this, the code is much the same as regular decision trees.\n\n::: panel-tabset\n### Python\n\nWe specify the `n_estimators` parameter here to be 500.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# create a pipeline with a scaler and the bagged decision tree model\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('bagged_dt', BaggingRegressor(estimator=DecisionTreeRegressor(random_state=4), n_estimators=50, random_state=4)) #500\n])\n\n# define our grid\nparam_grid = {\n    'bagged_dt__estimator__ccp_alpha': np.logspace(-4, 0, 5), # np.logspace(-4, 0, 20),\n    'bagged_dt__estimator__max_depth': list(range(1, 13)), # list(range(1, 21)),\n    'bagged_dt__estimator__min_samples_leaf': list(range(1, 13)) # list(range(1, 21))\n}\n\n# now lets search our grid for our optimal values\ngrid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;bagged_dt&#x27;,\n                                        BaggingRegressor(estimator=DecisionTreeRegressor(random_state=4),\n                                                         n_estimators=50,\n                                                         random_state=4))]),\n             n_jobs=-1,\n             param_grid={&#x27;bagged_dt__estimator__ccp_alpha&#x27;: array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n                         &#x27;bagged_dt__estimator__max_depth&#x27;: [1, 2, 3, 4, 5, 6,\n                                                             7, 8, 9, 10, 11,\n                                                             12],\n                         &#x27;bagged_dt__estimator__min_samples_leaf&#x27;: [1, 2, 3, 4,\n                                                                    5, 6, 7, 8,\n                                                                    9, 10, 11,\n                                                                    12]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;bagged_dt&#x27;,\n                                        BaggingRegressor(estimator=DecisionTreeRegressor(random_state=4),\n                                                         n_estimators=50,\n                                                         random_state=4))]),\n             n_jobs=-1,\n             param_grid={&#x27;bagged_dt__estimator__ccp_alpha&#x27;: array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n                         &#x27;bagged_dt__estimator__max_depth&#x27;: [1, 2, 3, 4, 5, 6,\n                                                             7, 8, 9, 10, 11,\n                                                             12],\n                         &#x27;bagged_dt__estimator__min_samples_leaf&#x27;: [1, 2, 3, 4,\n                                                                    5, 6, 7, 8,\n                                                                    9, 10, 11,\n                                                                    12]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;bagged_dt&#x27;,\n                 BaggingRegressor(estimator=DecisionTreeRegressor(random_state=4),\n                                  n_estimators=50, random_state=4))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">bagged_dt: BaggingRegressor</label><div class=\"sk-toggleable__content\"><pre>BaggingRegressor(estimator=DecisionTreeRegressor(random_state=4),\n                 n_estimators=50, random_state=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=4)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# predict on the test set\ny_pred = grid_search.predict(X_test)\nbag_tree_rmse = mean_squared_error(y_test, y_pred, squared=False)\nprint(\"Best Bagged Decision Tree parameters: \", grid_search.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest Bagged Decision Tree parameters:  {'bagged_dt__estimator__ccp_alpha': 0.001, 'bagged_dt__estimator__max_depth': 12, 'bagged_dt__estimator__min_samples_leaf': 2}\n```\n:::\n\n```{.python .cell-code}\nprint(\"Bagged Decision Tree RMSE: \", bag_tree_rmse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBagged Decision Tree RMSE:  4.996459665683262\n```\n:::\n\n```{.python .cell-code}\ndel(pipe, param_grid, grid_search, y_pred)\n```\n:::\n\n\nOur RMSE is improving!\n\n### R\nAs usual, we follow the same approach in R. We specify the number of trees we want to use in the final model using `times=500`. \n\n::: {.cell}\n\n```{.r .cell-code}\n# model specification\nbagdt_spec <- bag_tree(\n    mode = \"regression\",\n    tree_depth = tune(),\n    min_n = tune(),\n    cost_complexity = tune()\n  ) %>%\n  set_engine(\"rpart\", times = 50) |> # times = 500\n  set_mode(\"regression\")\n\n# checking out our hyperparameters\nbagdt_params <- parameters(cost_complexity(), tree_depth(), min_n())\nbagdt_grid <- grid_max_entropy(bagdt_params, size = 10, iter = 5)\n\n# make a workflow\nbagdt_wf <- workflow() |>\n  add_model(bagdt_spec) |>\n  add_recipe(rec)\n\n# Tuning\nn_cores <- detectCores() - 1 # Use all available cores except one\nregisterDoParallel(cores = n_cores)\nbagdt_rs <- tune_grid(\n  bagdt_wf,\n  resamples = folds,\n  grid = bagdt_grid,\n  metrics = metric_set(yardstick::rmse),\n  control = control_grid(save_pred = TRUE, parallel_over = \"everything\")\n)\n\n# Get the best hyperparameters\nbest_bagdt_params <- bagdt_rs |> \n  show_best(\"rmse\") |> \n  slice(1) |> \n  select(cost_complexity, tree_depth, min_n)\n\nbest_cc_bagdt <- best_bagdt_params$cost_complexity\nbest_depth_bagdt <- best_bagdt_params$tree_depth\nbest_min_n_bagdt <- best_bagdt_params$min_n\n\nshow_best(bagdt_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã 9\n  cost_complexity tree_depth min_n .metric .estimaâ¦Â¹  mean     n std_err .config\n            <dbl>      <int> <int> <chr>   <chr>     <dbl> <int>   <dbl> <chr>  \n1        1.04e- 5          8     3 rmse    standard   6.35     5   0.588 Preproâ¦\n2        4.19e- 8          6     7 rmse    standard   6.41     5   0.571 Preproâ¦\n3        1.21e- 5          7    26 rmse    standard   6.42     5   0.581 Preproâ¦\n4        2.17e- 6          6     5 rmse    standard   6.47     5   0.557 Preproâ¦\n5        8.60e-10         12    34 rmse    standard   6.51     5   0.566 Preproâ¦\n# â¦ with abbreviated variable name Â¹â.estimator\n```\n:::\n:::\n\n\nWe can again use the handy `autoplot()` function to visualize our best hyperparameter combinations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(bagdt_rs)\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nAnd finally, we use our best hyperparameter values to construct our final model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the final decision tree model with the best hyperparameters\nbagdt_final <- bag_tree(\n  cost_complexity = best_cc_bagdt,\n  tree_depth = best_depth_bagdt,\n  min_n = best_min_n_bagdt\n) %>%\n  set_engine(\"rpart\") %>%\n  set_mode(\"regression\")\n\n\n# Fit the final model on the whole training set\nbagdt_final_fit <- bagdt_wf %>%\n  update_model(bagdt_final) %>%\n  fit(data = training)\n\n# Make predictions on the holdout set and compute the RMSE\nbagdt_testing_preds <- predict(bagdt_final_fit, testing) |> \n  bind_cols(testing) |> \n  mutate(truth = as.double(DIC), estimate = as.double(.pred)) |> \n  metrics(truth = truth, estimate = estimate)\n\nbagdt_rmse <- bagdt_testing_preds %>% filter(.metric == \"rmse\") |>  pull(.estimate)\nprint(paste0(\"Bagged Tree RMSE:\", bagdt_rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Bagged Tree RMSE:5.94843583170231\"\n```\n:::\n\n```{.r .cell-code}\nrm(bagdt_final, bagdt_final_fit, bagdt_grid, bagdt_params, bagdt_rs, bagdt_spec, bagdt_testing_preds, bagdt_wf, best_bagdt_params)\n```\n:::\n\n:::\n\nOur RMSE is getting better! Bagging our decision trees help us combat the overfitting that ordinary decision trees are prone to. However, there are still a few more ways we can improve this model!\n\n# Random Forest\n\nOur Bagged Tree RMSE was better than our normal decision tree algorithm, but we can still make this better! Bagging aggregates the predictions across all the trees, which reduces the variance of the overall procedure and results in improved predictive performance. However, simply bagging trees results in tree correlation that limits the effect of variance reduction. Random forests are built using the same fundamental principles as decision trees and bagging, but inject further randomness in the process which further reduces the variance.\n\nRandom forests help to reduce tree correlation by injecting more randomness into the tree-growing process. Specifically, while growing a decision tree during the bagging process, random forests specify a subset of the features to be used in each tree. This parameter is called `m_try`, and it controls the number of features to consider when randomly selecting a subset of features for each tree. For example, if there are 10 input features and `mtry` is set to 3, then for each tree in the Random Forest, a random subset of 3 features will be selected from the 10 input features. By controlling the number of features used for each tree, `mtry` helps to reduce the correlation between the trees and increase the diversity of the Random Forest. The optimal value for `m_try` depends on the problem, but a standard value for regression tasks is`mtry=(p/3)`, where `p` is the number of features present in our dataset.\n\n::: panel-tabset\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create a pipeline with a scaler and the random forest regressor\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('rf_regressor', RandomForestRegressor(random_state=4))\n])\n\n# Define the parameter grid for hyperparameter tuning\nparam_grid = {\n    'rf_regressor__n_estimators': list(range(100, 1000, 450)),  # number of trees list(range(100, 1000, 50))\n    'rf_regressor__max_features': list(range(1, X_train.shape[1] - 10)),  # mtry\n    'rf_regressor__min_samples_leaf': list(range(1, 10))  # min_n\n}\n\n# Perform GridSearchCV for hyperparameter tuning\ngrid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;rf_regressor&#x27;,\n                                        RandomForestRegressor(random_state=4))]),\n             n_jobs=-1,\n             param_grid={&#x27;rf_regressor__max_features&#x27;: [1, 2, 3, 4, 5, 6, 7, 8],\n                         &#x27;rf_regressor__min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6, 7,\n                                                            8, 9],\n                         &#x27;rf_regressor__n_estimators&#x27;: [100, 550]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;rf_regressor&#x27;,\n                                        RandomForestRegressor(random_state=4))]),\n             n_jobs=-1,\n             param_grid={&#x27;rf_regressor__max_features&#x27;: [1, 2, 3, 4, 5, 6, 7, 8],\n                         &#x27;rf_regressor__min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6, 7,\n                                                            8, 9],\n                         &#x27;rf_regressor__n_estimators&#x27;: [100, 550]},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;rf_regressor&#x27;, RandomForestRegressor(random_state=4))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=4)</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\ny_pred = grid_search.predict(X_test)\nrf_rmse = mean_squared_error(y_test, y_pred, squared=False)\nprint(\"Best Random Forest parameters: \", grid_search.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest Random Forest parameters:  {'rf_regressor__max_features': 6, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__n_estimators': 550}\n```\n:::\n\n```{.python .cell-code}\nprint(\"RMSE: \", rf_rmse)\n\n# Clear our environment\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE:  5.059267757009525\n```\n:::\n\n```{.python .cell-code}\ndel(pipe, param_grid, grid_search, y_pred)\n```\n:::\n\nOur RMSE is still improving!\n\n### R\nWe follow the same approach in R: \n\n::: {.cell}\n\n```{.r .cell-code}\n# specifying tuning parameters\nrandfor_spec <- rand_forest(\n  trees = tune(),\n  mtry = tune(),\n  min_n = tune()\n) |>\n  set_mode(\"regression\") |>\n  set_engine(\"ranger\")\n\n# Looking at hyperparameters\nrandf_grid <-grid_regular(trees(), min_n(), mtry(range(1:13)), levels = 5)\n\n# Define new workflow\nrf_workflow <- workflow() |>\n  add_model(randfor_spec) |>\n  add_recipe(rec)\n\n# Tuning\ndoParallel::registerDoParallel()\nrandf_rs <- tune_grid(\n  rf_workflow,\n  resamples = folds,\n  grid = randf_grid,\n  metrics = metric_set(yardstick::rmse),\n  control = control_grid(save_pred = TRUE, parallel_over = \"everything\")\n)\n```\n:::\n\n\nAs always, lets take a look at our best hyperparameter combinations:\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(randf_rs)\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the best hyperparameters\nbest_randf_params <- randf_rs |> \n  show_best(\"rmse\") |> \n  slice(1) |> \n  select(trees, mtry, min_n)\n\nbest_trees_rf <- best_randf_params$trees\nbest_mtry_rf <- best_randf_params$mtry\nbest_min_n_rf <- best_randf_params$min_n\n\nshow_best(randf_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     7  1500     2 rmse    standard    5.68     5   0.577 Preprocessor1_Model0â¦\n2     7  2000     2 rmse    standard    5.68     5   0.576 Preprocessor1_Model0â¦\n3     7  1000     2 rmse    standard    5.68     5   0.573 Preprocessor1_Model0â¦\n4     7   500     2 rmse    standard    5.69     5   0.573 Preprocessor1_Model0â¦\n5     4  1500     2 rmse    standard    5.69     5   0.556 Preprocessor1_Model0â¦\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the final random forest model with the best hyperparameters\nrandf_final <- rand_forest(\n  trees = best_trees_rf,\n  mtry = best_mtry_rf,\n  min_n = best_min_n_rf\n) |>\n  set_mode(\"regression\") |>\n  set_engine(\"ranger\")\n\n\n# fit on the training\nrandf_final_fit <- rf_workflow |> \n  update_model(randf_final) |> \n  fit(data = training)\n\n# predict on the test, calculate RMSE\nrf_testing_preds <- predict(randf_final_fit, testing) |> \n  bind_cols(testing) |> \n  mutate(truth = as.double(DIC), estimate = as.double(.pred)) |> \n  metrics(truth = truth, estimate = estimate)\n\nrf_rmse <- rf_testing_preds %>% filter(.metric == \"rmse\") |>  pull(.estimate)\n\nrm(randf_grid, randf_rs, randfor_spec, rf_workflow)\nprint(paste0(\"Random Forest RMSE:\", rf_rmse))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Random Forest RMSE:5.047782925692\"\n```\n:::\n:::\n\n:::\n\nOur model is still improving, but there is another powerful adjustment we can make to it.\n\n\n# Gradient Boosting\nWhereas random forests build an ensemble of deep independent trees, Gradient Boosting Machines (GBMS) build an ensemble of shallow trees in sequence, with each tree learning and improving on the previous one. Independently, these trees are relatively weak predictive models, but they can be boosted to produce a powerful ensemble of trees.\n\nThe boosting idea is to add new models to the ensemble sequentially. We start with a weak model, and sequentially boost its performance by continuing to build new trees, where each new tree in the sequence remedies where the previous one made had the largest prediction errors. To quantify the amount of information gained by each new tree, we use a loss function, which measures the difference between the predicted values and the true values for the training examples. The goal is to minimize this function, which means that we want to find the set of parameters for each new tree that best fit the data. To find the optimal set of parameters, we use gradient descent, which is an optimization algorithm that works by iteratively improving the parameters of the model to minimize the loss function. At each iteration, we calculate the gradient of the loss function with respect to the model parameters, and we use this gradient to update the parameters in a direction that minimizes the loss function. We continue this process until we reach a minimum value of the loss function or a stopping criterion is met. The important hyperparameter we use for this is known as the learning rate. The learning rate specifies how fast we want to descend down the gradient. Too large, and we might miss the minimum of the loss function. Too small, and we'll need to many iterations to find the minimum.\n\nWe're going to take a different approach to tuning this model. Instead of specifying all the parameters we want to tune in one step, we're going to break it up. First, we'll find the optimal learning rate. Based off the optimal learning rate, we'll then tune the tree specific parameters (`min_n`/`xgb__min_child_weight`, `tree_depth`/`xgb__max_depth`, `loss_reduction`/`xgb__gamma`, `xgb__n_estimators` in python, we'll set the number of trees manually in R). Then, based off these optimal values of the tree specific parameters, we'll tune the stochastic parameters (`sample_size`/`xgb__subsample`, `mtry`/`xgb__colsample_bytree`).  \n\n\n::: panel-tabset\n### Python\nInstead of using sklearn for this algorithm in python, we're going to use the XGB library. This is a library built specifically for gradient boosting, and will increase our computational efficiency.\n\n::: {.cell}\n\n```{.python .cell-code}\n# instantiate our GBM\nxgb = XGBRegressor()\n\n# make our pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('xgb', xgb)\n])\n# First, tune the learning rate\nlearning_rates = np.linspace(0.01, 0.6, 10) # np.linspace(0.01, 0.6, 100)\nparam_grid_learning_rate = {\n    'xgb__learning_rate': learning_rates\n}\n\ngrid_search_lr = GridSearchCV(\n    pipeline, param_grid_learning_rate, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1\n)\ngrid_search_lr.fit(X_train, y_train)\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;xgb&#x27;,\n                                        XGBRegressor(base_score=None,\n                                                     booster=None,\n                                                     callbacks=None,\n                                                     colsample_bylevel=None,\n                                                     colsample_bynode=None,\n                                                     colsample_bytree=None,\n                                                     early_stopping_rounds=None,\n                                                     enable_categorical=False,\n                                                     eval_metric=None,\n                                                     feature_types=None,\n                                                     gamma=None, gpu_id=None,\n                                                     grow_policy=None,\n                                                     importance_type=Non...\n                                                     max_leaves=None,\n                                                     min_child_weight=None,\n                                                     missing=nan,\n                                                     monotone_constraints=None,\n                                                     n_estimators=100,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     predictor=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={&#x27;xgb__learning_rate&#x27;: array([0.01      , 0.07555556, 0.14111111, 0.20666667, 0.27222222,\n       0.33777778, 0.40333333, 0.46888889, 0.53444444, 0.6       ])},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;xgb&#x27;,\n                                        XGBRegressor(base_score=None,\n                                                     booster=None,\n                                                     callbacks=None,\n                                                     colsample_bylevel=None,\n                                                     colsample_bynode=None,\n                                                     colsample_bytree=None,\n                                                     early_stopping_rounds=None,\n                                                     enable_categorical=False,\n                                                     eval_metric=None,\n                                                     feature_types=None,\n                                                     gamma=None, gpu_id=None,\n                                                     grow_policy=None,\n                                                     importance_type=Non...\n                                                     max_leaves=None,\n                                                     min_child_weight=None,\n                                                     missing=nan,\n                                                     monotone_constraints=None,\n                                                     n_estimators=100,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     predictor=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={&#x27;xgb__learning_rate&#x27;: array([0.01      , 0.07555556, 0.14111111, 0.20666667, 0.27222222,\n       0.33777778, 0.40333333, 0.46888889, 0.53444444, 0.6       ])},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=None, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_threshold=None,\n                              max_cat_to_onehot=None, max_delta_step=None,\n                              max_depth=None, max_leaves=None,\n                              min_child_weight=None, missing=nan,\n                              monotone_constraints=None, n_estimators=100,\n                              n_jobs=None, num_parallel_tree=None,\n                              predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\nbest_learning_rate = grid_search_lr.best_params_['xgb__learning_rate']\nprint(f\"Best learning rate: {best_learning_rate}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest learning rate: 0.33777777777777773\n```\n:::\n:::\n\n\nNow, with our best learning rate, we'll tune the tree-specific parameters. Note that the names of these hyperparameters have changed slightly since we're using a different package.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Tree-specific parameters\nparam_grid_tree = {\n    'xgb__min_child_weight': range(1, 11, 3), # range(1, 21, 1),\n    'xgb__max_depth': range(1, 11, 3), # range(1, 21, 1),\n    'xgb__gamma': np.linspace(0, 1, 5), # np.linspace(0, 1, 20),\n    'xgb__n_estimators': range(100, 1500, 700)  # adjust the number of trees np.linspace(100, 1500, 30) \n}\n\n# Set the learning rate \npipeline.set_params(xgb__learning_rate=best_learning_rate)\n\n# find our best tree-specific parameters\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=None, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=None,\n                              max_leaves=None, min_child_weight=None,\n                              missing=nan, monotone_constraints=None,\n                              n_estimators=100, n_jobs=None,\n                              num_parallel_tree=None, predictor=None,\n                              random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=None, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=None,\n                              max_leaves=None, min_child_weight=None,\n                              missing=nan, monotone_constraints=None,\n                              n_estimators=100, n_jobs=None,\n                              num_parallel_tree=None, predictor=None,\n                              random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.33777777777777773,\n             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\ngrid_search_tree = GridSearchCV(\n    pipeline, param_grid_tree, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1\n)\ngrid_search_tree.fit(X_train, y_train)\n\n# Get the best tree-specific parameters\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;xgb&#x27;,\n                                        XGBRegressor(base_score=None,\n                                                     booster=None,\n                                                     callbacks=None,\n                                                     colsample_bylevel=None,\n                                                     colsample_bynode=None,\n                                                     colsample_bytree=None,\n                                                     early_stopping_rounds=None,\n                                                     enable_categorical=False,\n                                                     eval_metric=None,\n                                                     feature_types=None,\n                                                     gamma=None, gpu_id=None,\n                                                     grow_policy=None,\n                                                     importance_type=Non...\n                                                     min_child_weight=None,\n                                                     missing=nan,\n                                                     monotone_constraints=None,\n                                                     n_estimators=100,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     predictor=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={&#x27;xgb__gamma&#x27;: array([0.  , 0.25, 0.5 , 0.75, 1.  ]),\n                         &#x27;xgb__max_depth&#x27;: range(1, 11, 3),\n                         &#x27;xgb__min_child_weight&#x27;: range(1, 11, 3),\n                         &#x27;xgb__n_estimators&#x27;: range(100, 1500, 700)},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;xgb&#x27;,\n                                        XGBRegressor(base_score=None,\n                                                     booster=None,\n                                                     callbacks=None,\n                                                     colsample_bylevel=None,\n                                                     colsample_bynode=None,\n                                                     colsample_bytree=None,\n                                                     early_stopping_rounds=None,\n                                                     enable_categorical=False,\n                                                     eval_metric=None,\n                                                     feature_types=None,\n                                                     gamma=None, gpu_id=None,\n                                                     grow_policy=None,\n                                                     importance_type=Non...\n                                                     min_child_weight=None,\n                                                     missing=nan,\n                                                     monotone_constraints=None,\n                                                     n_estimators=100,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     predictor=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={&#x27;xgb__gamma&#x27;: array([0.  , 0.25, 0.5 , 0.75, 1.  ]),\n                         &#x27;xgb__max_depth&#x27;: range(1, 11, 3),\n                         &#x27;xgb__min_child_weight&#x27;: range(1, 11, 3),\n                         &#x27;xgb__n_estimators&#x27;: range(100, 1500, 700)},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=None, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=None,\n                              max_leaves=None, min_child_weight=None,\n                              missing=nan, monotone_constraints=None,\n                              n_estimators=100, n_jobs=None,\n                              num_parallel_tree=None, predictor=None,\n                              random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.33777777777777773,\n             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\nbest_min_child_weight = grid_search_tree.best_params_['xgb__min_child_weight']\nbest_max_depth = grid_search_tree.best_params_['xgb__max_depth']\nbest_gamma = grid_search_tree.best_params_['xgb__gamma']\nbest_n_estimators = grid_search_tree.best_params_['xgb__n_estimators']\n\nprint(f\"Best min_n: {best_min_child_weight}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest min_n: 1\n```\n:::\n\n```{.python .cell-code}\nprint(f\"Best max_depth: {best_max_depth}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest max_depth: 4\n```\n:::\n\n```{.python .cell-code}\nprint(f\"Best lost_reduction: {best_gamma}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest lost_reduction: 0.5\n```\n:::\n\n```{.python .cell-code}\nprint(f\"Best n_trees: {best_n_estimators}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest n_trees: 800\n```\n:::\n:::\n\n\nNow that we have the tree-specific parameters tuned, we can move on to the stochastic hyperparameters. \n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Stochastic parameters\nparam_grid_stochastic = {\n    'xgb__subsample': np.linspace(0.5, 1, 5), #np.linspace(0.5, 1, 20)\n    'xgb__colsample_bytree': np.linspace(1, 15, 5), # np.linspace(1, 15, 15)\n}\n\n# Use the best learning rate and tree-specific parameters \npipeline.set_params(\n    xgb__learning_rate=best_learning_rate,\n    xgb__min_child_weight=best_min_child_weight,\n    xgb__max_depth=best_max_depth,\n    xgb__gamma=best_gamma,\n    xgb__n_estimators=best_n_estimators\n)\n\n# Perform GridSearchCV for stochastic parameters\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=0.5, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=4, max_leaves=None,\n                              min_child_weight=1, missing=nan,\n                              monotone_constraints=None, n_estimators=800,\n                              n_jobs=None, num_parallel_tree=None,\n                              predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=0.5, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=4, max_leaves=None,\n                              min_child_weight=1, missing=nan,\n                              monotone_constraints=None, n_estimators=800,\n                              n_jobs=None, num_parallel_tree=None,\n                              predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.5, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.33777777777777773,\n             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=4, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=800, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\ngrid_search_stochastic = GridSearchCV(\n    pipeline, param_grid_stochastic, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1\n)\ngrid_search_stochastic.fit(X_train, y_train)\n\n# Get the best stochastic parameters\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;xgb&#x27;,\n                                        XGBRegressor(base_score=None,\n                                                     booster=None,\n                                                     callbacks=None,\n                                                     colsample_bylevel=None,\n                                                     colsample_bynode=None,\n                                                     colsample_bytree=None,\n                                                     early_stopping_rounds=None,\n                                                     enable_categorical=False,\n                                                     eval_metric=None,\n                                                     feature_types=None,\n                                                     gamma=0.5, gpu_id=None,\n                                                     grow_policy=None,\n                                                     importance_type=None...\n                                                     max_delta_step=None,\n                                                     max_depth=4,\n                                                     max_leaves=None,\n                                                     min_child_weight=1,\n                                                     missing=nan,\n                                                     monotone_constraints=None,\n                                                     n_estimators=800,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     predictor=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={&#x27;xgb__colsample_bytree&#x27;: array([ 1. ,  4.5,  8. , 11.5, 15. ]),\n                         &#x27;xgb__subsample&#x27;: array([0.5  , 0.625, 0.75 , 0.875, 1.   ])},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;xgb&#x27;,\n                                        XGBRegressor(base_score=None,\n                                                     booster=None,\n                                                     callbacks=None,\n                                                     colsample_bylevel=None,\n                                                     colsample_bynode=None,\n                                                     colsample_bytree=None,\n                                                     early_stopping_rounds=None,\n                                                     enable_categorical=False,\n                                                     eval_metric=None,\n                                                     feature_types=None,\n                                                     gamma=0.5, gpu_id=None,\n                                                     grow_policy=None,\n                                                     importance_type=None...\n                                                     max_delta_step=None,\n                                                     max_depth=4,\n                                                     max_leaves=None,\n                                                     min_child_weight=1,\n                                                     missing=nan,\n                                                     monotone_constraints=None,\n                                                     n_estimators=800,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     predictor=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={&#x27;xgb__colsample_bytree&#x27;: array([ 1. ,  4.5,  8. , 11.5, 15. ]),\n                         &#x27;xgb__subsample&#x27;: array([0.5  , 0.625, 0.75 , 0.875, 1.   ])},\n             scoring=&#x27;neg_root_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=0.5, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=4, max_leaves=None,\n                              min_child_weight=1, missing=nan,\n                              monotone_constraints=None, n_estimators=800,\n                              n_jobs=None, num_parallel_tree=None,\n                              predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.5, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.33777777777777773,\n             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=4, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=800, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\nbest_subsample = grid_search_stochastic.best_params_['xgb__subsample']\nbest_colsample_bytree = grid_search_stochastic.best_params_['xgb__colsample_bytree']\n\nprint(f\"Best subsample: {best_subsample}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest subsample: 1.0\n```\n:::\n\n```{.python .cell-code}\nprint(f\"Best colsample_bytree: {best_colsample_bytree}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBest colsample_bytree: 1.0\n```\n:::\n:::\n\n\nAnd finally, we can use the best values for all of these hyperparameters to build our final model.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Train the final model with the best hyperparameters on the training set (excluding the holdout set)\nfinal_pipeline = pipeline.set_params(\n    xgb__learning_rate=best_learning_rate,\n    xgb__min_child_weight=best_min_child_weight,\n    xgb__max_depth=best_max_depth,\n    xgb__gamma=best_gamma,\n    xgb__n_estimators=best_n_estimators,\n    xgb__subsample=best_subsample,\n    xgb__colsample_bytree=best_colsample_bytree\n)\nfinal_pipeline.fit(X_train, y_train)\n\n# Validate the final model on the holdout set\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=1.0, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=0.5, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=4, max_leaves=None,\n                              min_child_weight=1, missing=nan,\n                              monotone_constraints=None, n_estimators=800,\n                              n_jobs=None, num_parallel_tree=None,\n                              predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=1.0, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              feature_types=None, gamma=0.5, gpu_id=None,\n                              grow_policy=None, importance_type=None,\n                              interaction_constraints=None,\n                              learning_rate=0.33777777777777773, max_bin=None,\n                              max_cat_threshold=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=4, max_leaves=None,\n                              min_child_weight=1, missing=nan,\n                              monotone_constraints=None, n_estimators=800,\n                              n_jobs=None, num_parallel_tree=None,\n                              predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=1.0, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=0.5, gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.33777777777777773,\n             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=4, max_leaves=None,\n             min_child_weight=1, missing=nan, monotone_constraints=None,\n             n_estimators=800, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\ntest_preds = final_pipeline.predict(X_test)\ngb_rmse = mean_squared_error(y_test, test_preds, squared=False)\nprint(f\"test RMSE: {gb_rmse}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntest RMSE: 5.499163662927346\n```\n:::\n:::\n\n\n### R\n\nSimilarly in R, we start by tuning the learning rate. As we have before, we use a grid of values to test to find which produces the lowest RMSE on the training data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tune learning rate\ntune_lr <- boost_tree(learn_rate = tune()) |> \n  set_mode('regression') |> \n  set_engine(\"xgboost\") \n\n# make our cv grid\nlr_grid <- expand.grid(learn_rate = seq(0.0001, 0.5, length.out = 20)) # seq(0.0001, 0.5, length.out = 200))\n\n# now our workflow\ntune_wf_lr <- workflow() |> \n      add_model(tune_lr) |> \n      add_recipe(rec) \n\n# tuning\nfit_tune_lr <- tune_wf_lr |> \n      tune_grid(resamples = folds, grid = lr_grid)\n\nshow_best(fit_tune_lr, metric = \"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã 7\n  learn_rate .metric .estimator  mean     n std_err .config              \n       <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1      0.5   rmse    standard    7.38     5   0.552 Preprocessor1_Model20\n2      0.474 rmse    standard    7.51     5   0.543 Preprocessor1_Model19\n3      0.421 rmse    standard    7.57     5   0.487 Preprocessor1_Model17\n4      0.447 rmse    standard    7.64     5   0.576 Preprocessor1_Model18\n5      0.395 rmse    standard    7.66     5   0.560 Preprocessor1_Model16\n```\n:::\n\n```{.r .cell-code}\nbest_lr <- as.numeric(show_best(fit_tune_lr, metric = \"rmse\")[1,1])\n```\n:::\n\n\nUsing this learning rate, we then tune the tree specific parameters. Unlike our approach in python, we're fixing the number of trees to be 1000 in R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregisterDoParallel(cores = n_cores)\n# Specifying that we want to tune the tree-specific parameters\nlropt_tune_spec <-\n    boost_tree(\n    learn_rate = best_lr,\n    trees = 100, # 1000\n    min_n = tune(),\n    tree_depth = tune(),\n    loss_reduction = tune()\n  ) |>\n  set_engine(\"xgboost\") |>\n  set_mode('regression')\n\n# Setting up the parameters to be tuned and the grid to search over\ntree_params <- parameters(tree_depth(), min_n(), loss_reduction())\ntrees_grid <- grid_max_entropy(tree_params, size = 10, iter = 5) # size=20\n\n# Defining a new workflow, adding our models and tuning parameters\ntree_wf <- workflow() |> add_model(lropt_tune_spec) |> add_recipe(rec)\n\n#  tune our parameters\nfit_tune_trees <- tree_wf |> tune_grid(\n  resamples = folds,\n  grid = trees_grid,\n  metrics = metric_set(rmse),\n  control = control_grid(save_pred = TRUE, parallel_over = \"everything\")\n)\n\n# extract the best values\nshow_best(fit_tune_trees, metric =\"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã 9\n  min_n tree_depth loss_reduction .metric .estimator  mean     n std_err .config\n  <int>      <int>          <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>  \n1    16          4       4.78e- 8 rmse    standard    6.89     5   0.548 Preproâ¦\n2    39          4       1.81e+ 0 rmse    standard    6.90     5   0.415 Preproâ¦\n3    17          8       1.85e- 6 rmse    standard    7.09     5   0.393 Preproâ¦\n4    20         10       8.64e-10 rmse    standard    7.09     5   0.500 Preproâ¦\n5    36          6       3.85e-10 rmse    standard    7.10     5   0.539 Preproâ¦\n```\n:::\n\n```{.r .cell-code}\nopt_min_n <- as.numeric(show_best(fit_tune_trees, metric = \"rmse\")[1,1])\nopt_tree_depth <- as.numeric(show_best(fit_tune_trees, metric = \"rmse\")[1,2])\nopt_loss_red <- as.numeric(show_best(fit_tune_trees, metric = \"rmse\")[1,3])\n```\n:::\n\n\nWe now use our optimal tree parameters to tune the stochastic parameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregisterDoParallel(cores = n_cores)\n\n# Specifying that we want to tune the stoachastic-specific parameters\nstoch_tune_spec <-\n  boost_tree(\n    learn_rate = best_lr,\n    trees = 100, # 1000\n    min_n = opt_min_n,\n    tree_depth = opt_tree_depth,\n    loss_reduction = opt_loss_red,\n    mtry = tune(),\n    sample_size = tune()\n  ) |>\n  set_engine(\"xgboost\") |>\n  set_mode('regression')\n\n# Define the parameters\nstoch_params <- parameters(\n  finalize(mtry(), training),\n  sample_size= sample_prop())\n\n# Generate a grid of parameter values\nstoch_grid <- grid_max_entropy(stoch_params, size = 10, iter = 5)\n        \nstoch_tune_wf <- workflow() |> \n  add_model(stoch_tune_spec) |> \n  add_recipe(rec)\n\nfit_tune_stoch <- stoch_tune_wf |> tune_grid(\n  resamples = folds,\n  grid = stoch_grid,\n  metrics = metric_set(rmse),\n  control = control_grid(save_pred = TRUE, parallel_over = \"everything\")\n)\nshow_best(fit_tune_stoch, metric = \"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 Ã 8\n   mtry sample_size .metric .estimator  mean     n std_err .config              \n  <int>       <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1    13       0.925 rmse    standard    7.12     5   0.448 Preprocessor1_Model10\n2    17       0.544 rmse    standard    8.01     5   0.261 Preprocessor1_Model01\n3    14       0.575 rmse    standard    8.26     5   0.542 Preprocessor1_Model07\n4     5       0.952 rmse    standard    8.28     5   0.683 Preprocessor1_Model08\n5     9       0.483 rmse    standard    8.89     5   0.394 Preprocessor1_Model04\n```\n:::\n\n```{.r .cell-code}\nopt_mtry <- as.numeric(show_best(fit_tune_stoch, metric = \"rmse\")[1,1])\nopt_ss <- as.numeric(show_best(fit_tune_stoch, metric = \"rmse\")[1,2])\n```\n:::\n\n\nFinally, we add all of this into the final model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_model <- boost_tree(learn_rate = best_lr,\n                          trees = 100, # 1000\n                          min_n = opt_min_n,\n                          mtry = opt_mtry,\n                          tree_depth = opt_tree_depth,\n                          loss_reduction = opt_loss_red,\n                          sample_size = opt_ss,\n                          ) |>\n  set_mode(\"regression\") |>\n  set_engine(\"xgboost\", early_stopping_rounds = 50)\n\n# final_params <- extract_parameter_set_dials(final_model)\n# final_grid <- grid_max_entropy(final_params, size = 50, iter = 5)\n\nfinal_wf <- workflow() |>\n  add_model(final_model) |>\n  add_recipe(rec)\n\nfinal_fit <- final_wf |> fit(training)\n\n# predict on the test, calculate RMSE\ngb_testing_preds <- predict(final_fit, testing) |> \n  bind_cols(testing) |> \n  mutate(truth = as.double(DIC), estimate = as.double(.pred)) |> \n  metrics(truth = truth, estimate = estimate)\n\ngb_rmse <- gb_testing_preds %>% filter(.metric == \"rmse\") |>  pull(.estimate)\n\nprint(gb_rmse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.291353\n```\n:::\n:::\n\n:::\n\n# Support Vector Machine\nSupport Vector Machines (SVMs) are a little different than what we've done so far. The goal of SVMs in our case is to move our data into higher dimensions to find a hyperplane that best fits our data points, while balancing model complexity and error tolerance. SVMs accomplish this by transforming the input data into a higher-dimensional space using the kernel trick (implicitly transforming the data into a higher dimensional space without explicitly performing the transformation, this helps the algorithm capture complex relationships in the data without compromising too much computational efficiency). SVMs identify a subset of the training data, called support vectors, which are critical in determining the optimal hyperplane. Once the optimal hyperplane is found, new data points can be projected onto it to make predictions.\n\nThe kernel function is what maps the features to a higher-dimensional feature space. Although there are different types of kernel functions to choose from, the linear kernel function is the most appropriate for our data. The linear kernel function is particularly useful when the data is linearly separable or when a linear relationship exists between the features and the target variable.\n\n::: panel-tabset\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Create the pipeline\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('svm', SVR(kernel='linear'))\n])\n\n# Define the tuning grid\nparam_grid = {\n    'svm__C': np.logspace(-5, 5, 5), # np.logspace(-5, 5, 100),\n}\n\n# Perform grid search with cross-validation\ngrid = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\ngrid.fit(X_train, y_train)\n\n# Train the final model with the best parameters\n```\n\n::: {.cell-output-display}\n```{=html}\n<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;svm&#x27;, SVR(kernel=&#x27;linear&#x27;))]),\n             n_jobs=-1,\n             param_grid={&#x27;svm__C&#x27;: array([1.00000000e-05, 3.16227766e-03, 1.00000000e+00, 3.16227766e+02,\n       1.00000000e+05])},\n             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                                       (&#x27;svm&#x27;, SVR(kernel=&#x27;linear&#x27;))]),\n             n_jobs=-1,\n             param_grid={&#x27;svm__C&#x27;: array([1.00000000e-05, 3.16227766e-03, 1.00000000e+00, 3.16227766e+02,\n       1.00000000e+05])},\n             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;svm&#x27;, SVR(kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>\n```\n:::\n\n```{.python .cell-code}\nbest_params = grid.best_params_\nfinal_model = grid.best_estimator_\n\n# Make predictions on the validation set\ny_pred = final_model.predict(X_test)\n\n# Calculate the RMSE\nsvm_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(f\"RMSE: {svm_rmse}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRMSE: 4.8954038960758375\n```\n:::\n:::\n\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make our SVM model\nsvm_model <- svm_linear(\n  cost = tune()\n) |>\n  set_mode(\"regression\") |>\n  set_engine(\"kernlab\")\n\n# add model to workflow\nsvm_workflow <- workflow() |>\n  add_model(svm_model) |>\n  add_recipe(rec)\n\n# specify our tuning grid\ntune_svm_grid <- grid_regular(\n  cost(range = c(-10, 10)),\n  levels = 10\n)\n\n# tune our model\nfit_tune_svm <- svm_workflow |>\n  tune_grid(\n    resamples = folds,\n    grid = tune_svm_grid,\n    metrics = metric_set(rmse),\n    control = control_grid(save_pred = TRUE, parallel_over = \"everything\")\n  )\n\n# extract the best values for the hyperparameters\nbest_svm_params <- fit_tune_svm |>\n  show_best(metric = \"rmse\") |>\n  dplyr::slice(1) |>\n  select(cost)\n\n# use our best values in the final model\nfinal_svm_model <- svm_linear(\n  cost = best_svm_params$cost\n) |>\n  set_mode(\"regression\") |>\n  set_engine(\"kernlab\")\n\n# make a new workflow\nfinal_svm_wf <- workflow() |>\n  add_model(final_svm_model) |>\n  add_recipe(rec)\n\nfinal_svm_fit <- final_svm_wf |> fit(training)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Setting default kernel parameters  \n```\n:::\n\n```{.r .cell-code}\nfinal_svm_pred <- final_svm_fit |> predict(testing)\n\nsvm_rmse <- final_svm_pred |>\n  bind_cols(testing) |>\n  rmse(truth = DIC, estimate = .pred) %>%\n  pull(.estimate)\n\nprint(\"RMSE:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"RMSE:\"\n```\n:::\n\n```{.r .cell-code}\nprint(svm_rmse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.643437\n```\n:::\n:::\n\n:::\n\n\n# Evaluation\n\n::: panel-tabset\n\n::: {.cell}\n\n```{.python .cell-code}\n\nplt.clf()\nmodel_names = [\"LR\", \"Lasso\", \"Ridge\", \"KNN\", \"DT\", \"Bag DT\", \"RF\", \"GB\", \"SVM\"]\nrmses = [rmse_test_lr, ridge_rmse, lasso_rmse, rmse_knn, dt_rmse, bag_tree_rmse, rf_rmse, gb_rmse, svm_rmse]\n\nfig, ax = plt.subplots()\nax.bar(model_names, rmses)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<BarContainer object of 9 artists>\n```\n:::\n\n```{.python .cell-code}\nax.set_xlabel(\"Model\")\nax.set_ylabel(\"RMSE\")\nax.set_title(\"Model Performance Comparison\")\nplt.xticks(rotation = 45)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n([0, 1, 2, 3, 4, 5, 6, 7, 8], [Text(0, 0, 'LR'), Text(1, 0, 'Lasso'), Text(2, 0, 'Ridge'), Text(3, 0, 'KNN'), Text(4, 0, 'DT'), Text(5, 0, 'Bag DT'), Text(6, 0, 'RF'), Text(7, 0, 'GB'), Text(8, 0, 'SVM')])\n```\n:::\n\n```{.python .cell-code}\nplt.show()\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_names <- c(\"Linear Regression\", \"Lasso\", \"Ridge\", \"KNN\", \"Decision Tree\", \"Bagged DT\", \"Random Forest\", \"Gradient Boosting\", \"SVM\")\nrmses <- c(rmse_lr, lasso_rmse, ridge_rmse, rmse_knn, dt_rmse, bagdt_rmse, rf_rmse, gb_rmse, svm_rmse)\n\ndf_rmse <- data.frame(Model = model_names, RMSE = rmses)\n\nggplot(df_rmse, aes(x = Model, y = RMSE, fill = Model)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Model\", y = \"RMSE\", title = \"Model Performance Comparison\")\n```\n\n::: {.cell-output-display}\n![](ocean_chem_modeling_files/figure-html/unnamed-chunk-48-3.png){width=672}\n:::\n:::\n\n:::\n\n# Conclusion\n",
    "supporting": [
      "ocean_chem_modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/htmlwidgets-1.6.0/htmlwidgets.js\"></script>\n<script src=\"../../site_libs/jquery-1.12.4/jquery.min.js\"></script>\n<link href=\"../../site_libs/leaflet-1.3.1/leaflet.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/leaflet-1.3.1/leaflet.js\"></script>\n<link href=\"../../site_libs/leafletfix-1.0.0/leafletfix.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/proj4-2.6.2/proj4.min.js\"></script>\n<script src=\"../../site_libs/Proj4Leaflet-1.0.1/proj4leaflet.js\"></script>\n<link href=\"../../site_libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/leaflet-binding-2.1.1/leaflet.js\"></script>\n<script src=\"../../site_libs/leaflet-providers-1.9.0/leaflet-providers_1.9.0.js\"></script>\n<script src=\"../../site_libs/leaflet-providers-plugin-2.1.1/leaflet-providers-plugin.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}